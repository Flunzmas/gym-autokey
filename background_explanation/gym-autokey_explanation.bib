@article{amraniMLFVSurvey2018a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.03600},
  primaryClass = {cs},
  title = {{{ML}} + {{FV}} = {$\heartsuit$}? {{A Survey}} on the {{Application}} of {{Machine Learning}} to {{Formal Verification}}.},
  shorttitle = {{{ML}} + {{FV}} = \$\textbackslash{}heartsuit\$?},
  abstract = {Formal Veri cation (F ) and Machine Learning (M ) can seem incompatible due to their opposite mathematical foundations and their use in real-life problems: F mostly relies on discrete mathematics and aims at ensuring correctness; M o en relies on probabilistic models and consists of learning pa erns from training data. In this paper, we postulate that they are complementary in practice, and explore how M helps F in its classical approaches: static analysis, model-checking, theorem-proving, and S solving. We draw a landscape of the current practice and catalog some of the most prominent uses of M inside F tools, thus o ering a new perspective on F techniques that can help researchers and practitioners to be er locate the possible synergies. We discuss lessons learned from our work, point to possible improvements and o er visions for the future of the domain in the light of the science of so ware and systems modeling.},
  language = {en},
  journal = {arXiv:1806.03600 [cs]},
  author = {Amrani, Moussa and L{\'u}cio, Levi and Bibal, Adrien},
  month = jun,
  year = {2018},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Software Engineering},
  file = {files/93/Amrani et al. - 2018 - ML + FV = $heartsuit$ A Survey on the Applicatio.pdf}
}

@article{blanchetteLearningBasedFactSelector2016,
  title = {A {{Learning}}-{{Based Fact Selector}} for {{Isabelle}}/{{HOL}}},
  volume = {57},
  issn = {0168-7433, 1573-0670},
  abstract = {Sledgehammer integrates automatic theorem provers in the proof assistant Isabelle/HOL. A key component, the fact selector, heuristically ranks the thousands of facts (lemmas, definitions, or axioms) available and selects a subset, based on syntactic similarity to the current proof goal. We introduce MaSh, an alternative that learns from successful proofs. New challenges arose from our ``zero click'' vision: MaSh integrates seamlessly with the users' workflow, so that they benefit from machine learning without having to install software, set up servers, or guide the learning. MaSh outperforms the old fact selector on large formalizations.},
  language = {en},
  number = {3},
  journal = {J Autom Reasoning},
  doi = {10.1007/s10817-016-9362-8},
  author = {Blanchette, Jasmin Christian and Greenaway, David and Kaliszyk, Cezary and K{\"u}hlwein, Daniel and Urban, Josef},
  month = oct,
  year = {2016},
  pages = {219-244},
  file = {files/178/Blanchette et al. - 2016 - A Learning-Based Fact Selector for IsabelleHOL.pdf}
}

@phdthesis{bridgeMachineLearningAutomated,
  title = {Machine Learning and Automated Theorem Proving},
  abstract = {Computer programs to find formal proofs of theorems have a history going back nearly half a century. Originally designed as tools for mathematicians, modern applications of automated theorem provers and proof assistants are much more diverse. In particular they are used in formal methods to verify software and hardware designs to prevent costly, or life threatening, errors being introduced into systems from microchips to controllers for medical equipment or space rockets.},
  language = {en},
  author = {Bridge, James P},
  file = {files/104/Bridge - Machine learning and automated theorem proving.pdf}
}

@article{bridgeMachineLearningFirstOrder2014,
  title = {Machine {{Learning}} for {{First}}-{{Order Theorem Proving}}: {{Learning}} to {{Select}} a {{Good Heuristic}}},
  volume = {53},
  issn = {0168-7433, 1573-0670},
  shorttitle = {Machine {{Learning}} for {{First}}-{{Order Theorem Proving}}},
  abstract = {We applied two state-of-the-art machine learning techniques to the problem of selecting a good heuristic in a first-order theorem prover. Our aim was to demonstrate that sufficient information is available from simple feature measurements of a conjecture and axioms to determine a good choice of heuristic, and that the choice process can be automatically learned. Selecting from a set of 5 heuristics, the learned results are better than any single heuristic. The same results are also comparable to the prover's own heuristic selection method, which has access to 82 heuristics including the 5 used by our method, and which required additional human expertise to guide its design. One version of our system is able to decline proof attempts. This achieves a significant reduction in total time required, while at the same time causing only a moderate reduction in the number of theorems proved. To our knowledge no earlier system has had this capability.},
  language = {en},
  number = {2},
  journal = {J Autom Reasoning},
  doi = {10.1007/s10817-014-9301-5},
  author = {Bridge, James P. and Holden, Sean B. and Paulson, Lawrence C.},
  month = aug,
  year = {2014},
  pages = {141-172},
  file = {files/106/Bridge et al. - 2014 - Machine Learning for First-Order Theorem Proving .pdf}
}

@article{fuchsFeatureBasedLearningMethod,
  title = {A {{Feature}}-{{Based Learning Method}} for {{Theorem Proving}}},
  abstract = {Automated reasoning or theorem proving essentially amounts to solving search problems. Despite significant progress in recent years theorem provers still have manyshortcomings. The use of machine-learning techniques is acknowledgedas promising, but difficult to apply in the area of theorem proving. Wepropose here to learn search-guiding heuristics by employing features in a simple, yet effective manner.Features are used to adapt a heuristic to a solved source problem. The adapted heuristic can then be utilized profitably for solving related target problems. Experiments have demonstrated that the approach not only allows for significant speed-ups, but also makes it possible to prove problems that were out of reach before.},
  language = {en},
  author = {Fuchs, Matthias},
  pages = {6},
  file = {files/110/Fuchs - A Feature-Based Learning Method for Theorem Provin.pdf}
}

@article{kaliszykLearningAssistedAutomatedReasoning2012,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1211.7012},
  primaryClass = {cs},
  title = {Learning-{{Assisted Automated Reasoning}} with {{Flyspeck}}},
  abstract = {The considerable mathematical knowledge encoded by the Flyspeck project is combined with external automated theorem provers (ATPs) and machine-learning premise selection methods trained on the Flyspeck proofs, producing an AI system capable of proving a wide range of mathematical conjectures automatically. The performance of this architecture is evaluated in a bootstrapping scenario emulating the development of Flyspeck from axioms to the last theorem, each time using only the previous theorems and proofs. It is shown that 39\% of the 14185 theorems could be proved in a push-button mode (without any high-level advice and user interaction) in 30 seconds of real time on a fourteen-CPU workstation.},
  language = {en},
  journal = {arXiv:1211.7012 [cs]},
  author = {Kaliszyk, Cezary and Urban, Josef},
  month = nov,
  year = {2012},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Logic in Computer Science,Computer Science - Digital Libraries},
  file = {files/112/Kaliszyk and Urban - 2012 - Learning-Assisted Automated Reasoning with Flyspec.pdf}
}

@article{kaliszykMachineLearnerAutomated2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1402.2359},
  primaryClass = {cs},
  title = {Machine {{Learner}} for {{Automated Reasoning}} 0.4 and 0.5},
  abstract = {Machine Learner for Automated Reasoning (MaLARea) is a learning and reasoning system for proving in large formal libraries where thousands of theorems are available when attacking a new conjecture, and a large number of related problems and proofs can be used to learn specific theorem-proving knowledge. The last version of the system has by a large margin won the 2013 CASC LTB competition. This paper describes the motivation behind the methods used in MaLARea, discusses the general approach and the issues arising in evaluation of such system, and describes the Mizar@Turing100 and CASC-24 versions of MaLARea.},
  language = {en},
  journal = {arXiv:1402.2359 [cs]},
  author = {Kaliszyk, Cezary and Urban, Josef and Vysko{\v c}il, Ji{\v r}{\'i}},
  month = feb,
  year = {2014},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Logic in Computer Science},
  file = {files/114/Kaliszyk et al. - 2014 - Machine Learner for Automated Reasoning 0.4 and 0..pdf}
}

@article{kaliszykEfficientSemanticFeatures,
  title = {Efficient {{Semantic Features}} for {{Automated Reasoning}} over {{Large Theories}}},
  abstract = {Large formal mathematical knowledge bases encode considerable parts of advanced mathematics and exact science, allowing deep semantic computer assistance and verification of complicated theories down to the atomic logical rules. An essential part of automated reasoning over such large theories are methods learning selection of relevant knowledge from the thousands of proofs in the corpora. Such methods in turn rely on efficiently computable features characterizing the highly structured and inter-related mathematical statements.},
  language = {en},
  author = {Kaliszyk, Cezary and Urban, Josef and Vyskocil, Jiri},
  pages = {7},
  file = {files/116/Kaliszyk et al. - Efficient Semantic Features for Automated Reasonin.pdf}
}

@article{komendantskayaMachineLearningProof2013,
  title = {Machine {{Learning}} in {{Proof General}}: {{Interfacing Interfaces}}},
  volume = {118},
  issn = {2075-2180},
  shorttitle = {Machine {{Learning}} in {{Proof General}}},
  abstract = {We present ML4PG \textemdash{} a machine learning extension for Proof General. It allows users to gather proof statistics related to shapes of goals, sequences of applied tactics, and proof tree structures from the libraries of interactive higher-order proofs written in Coq and SSReflect. The gathered data is clustered using the state-of-the-art machine learning algorithms available in MATLAB and Weka. ML4PG provides automated interfacing between Proof General and MATLAB/Weka. The results of clustering are used by ML4PG to provide proof hints in the process of interactive proof development. Key words: Interactive Theorem Proving, User Interfaces, Proof General, Coq, SSReflect, Machine Learning, Clustering.},
  language = {en},
  journal = {Electron. Proc. Theor. Comput. Sci.},
  doi = {10.4204/EPTCS.118.2},
  author = {Komendantskaya, Ekaterina and Heras, J{\'o}nathan and Grov, Gudmund},
  month = jul,
  year = {2013},
  pages = {15-41},
  file = {files/118/Komendantskaya et al. - 2013 - Machine Learning in Proof General Interfacing Int.pdf}
}

@incollection{kuhlweinMaShMachineLearning2013,
  address = {{Berlin, Heidelberg}},
  title = {{{MaSh}}: {{Machine Learning}} for {{Sledgehammer}}},
  volume = {7998},
  isbn = {978-3-642-39633-5 978-3-642-39634-2},
  shorttitle = {{{MaSh}}},
  abstract = {Sledgehammer integrates automatic theorem provers in the proof assistant Isabelle/HOL. A key component, the relevance filter, heuristically ranks the thousands of facts available and selects a subset, based on syntactic similarity to the current goal. We introduce MaSh, an alternative that learns from successful proofs. New challenges arose from our ``zero-click'' vision: MaSh should integrate seamlessly with the users' workflow, so that they benefit from machine learning without having to install software, set up servers, or guide the learning. The underlying machinery draws on recent research in the context of Mizar and HOL Light, with a number of enhancements. MaSh outperforms the old relevance filter on large formalizations, and a particularly strong filter is obtained by combining the two filters.},
  language = {en},
  booktitle = {Interactive {{Theorem Proving}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {K{\"u}hlwein, Daniel and Blanchette, Jasmin Christian and Kaliszyk, Cezary and Urban, Josef},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Blazy, Sandrine and {Paulin-Mohring}, Christine and Pichardie, David},
  year = {2013},
  pages = {35-50},
  file = {files/120/Kühlwein et al. - 2013 - MaSh Machine Learning for Sledgehammer.pdf},
  doi = {10.1007/978-3-642-39634-2\_6}
}

@article{kuhlweinMaLeSFrameworkAutomatic2015,
  title = {{{MaLeS}}: {{A Framework}} for {{Automatic Tuning}} of {{Automated Theorem Provers}}},
  volume = {55},
  issn = {0168-7433, 1573-0670},
  shorttitle = {{{MaLeS}}},
  abstract = {MaLeS is an automatic tuning framework for automated theorem provers. It provides solutions for both the strategy finding as well as the strategy scheduling problem. This paper describes the tool and the methods used in it, and evaluates its performance on three automated theorem provers: E, LEO-II and Satallax. On a representative subset of the TPTP library a MaLeS-tuned prover solves on average 8.67 \% more problems than the prover with its default settings.},
  language = {en},
  number = {2},
  journal = {J Autom Reasoning},
  doi = {10.1007/s10817-015-9329-1},
  author = {K{\"u}hlwein, Daniel and Urban, Josef},
  month = aug,
  year = {2015},
  pages = {91-116},
  file = {files/122/Kühlwein and Urban - 2015 - MaLeS A Framework for Automatic Tuning of Automat.pdf}
}

@article{loosDeepNetworkGuided2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1701.06972},
  primaryClass = {cs},
  title = {Deep {{Network Guided Proof Search}}},
  abstract = {Deep learning techniques lie at the heart of several significant AI advances in recent years including object recognition and detection, image captioning, machine translation, speech recognition and synthesis, and playing the game of Go.},
  language = {en},
  journal = {arXiv:1701.06972 [cs]},
  author = {Loos, Sarah and Irving, Geoffrey and Szegedy, Christian and Kaliszyk, Cezary},
  month = jan,
  year = {2017},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Logic in Computer Science},
  file = {files/124/Loos et al. - 2017 - Deep Network Guided Proof Search.pdf}
}

@misc{inriaIntroductionContentsCoq,
  title = {Introduction and {{Contents}} \textemdash{} {{Coq}} 8.9.0 Documentation},
  journal = {Coq 8.9.0 Documentation},
  howpublished = {https://coq.inria.fr/doc/},
  author = {{Inria}},
  file = {files/126/doc.html}
}

@article{mengLightweightRelevanceFiltering2009,
  title = {Lightweight Relevance Filtering for Machine-Generated Resolution Problems},
  volume = {7},
  issn = {15708683},
  abstract = {Irrelevant clauses in resolution problems increase the search space, making it hard to find proofs in a reasonable time. Simple relevance filtering methods, based on counting function symbols in clauses, improve the success rate for a variety of automatic theorem provers and with various initial settings. We have designed these techniques as part of a project to link automatic theorem provers to the interactive theorem prover Isabelle. They should be applicable to other situations where the resolution problems are produced mechanically and where completeness is less important than achieving a high success rate with limited processor time.},
  language = {en},
  number = {1},
  journal = {Journal of Applied Logic},
  doi = {10.1016/j.jal.2007.07.004},
  author = {Meng, Jia and Paulson, Lawrence C.},
  month = mar,
  year = {2009},
  pages = {41-57},
  file = {files/128/Meng and Paulson - 2009 - Lightweight relevance filtering for machine-genera.pdf}
}

@article{mouConvolutionalNeuralNetworks2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1409.5718},
  primaryClass = {cs},
  title = {Convolutional {{Neural Networks}} over {{Tree Structures}} for {{Programming Language Processing}}},
  abstract = {Programming language processing (similar to natural language processing) is a hot research topic in the field of software engineering; it has also aroused growing interest in the artificial intelligence community. However, different from a natural language sentence, a program contains rich, explicit, and complicated structural information. Hence, traditional NLP models may be inappropriate for programs. In this paper, we propose a novel tree-based convolutional neural network (TBCNN) for programming language processing, in which a convolution kernel is designed over programs' abstract syntax trees to capture structural information. TBCNN is a generic architecture for programming language processing; our experiments show its effectiveness in two different program analysis tasks: classifying programs according to functionality, and detecting code snippets of certain patterns. TBCNN outperforms baseline methods, including several neural models for NLP.},
  language = {en},
  journal = {arXiv:1409.5718 [cs]},
  author = {Mou, Lili and Li, Ge and Zhang, Lu and Wang, Tao and Jin, Zhi},
  month = sep,
  year = {2014},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering,Computer Science - Neural and Evolutionary Computing},
  file = {files/131/Mou et al. - 2014 - Convolutional Neural Networks over Tree Structures.pdf}
}

@article{schulzBrainiacTheoremProver,
  title = {E \textendash{} {{A Brainiac Theorem Prover}}},
  abstract = {We describe the superposition-based theorem prover E. E is a sound and complete prover for clausal first order logic with equality. Important properties of the prover include strong redundancy elimination criteria, the DISCOUNT loop proof procedure, a very flexible interface for specifying search control heuristics, and an efficient inference engine. We also discuss strength and weaknesses of the system.},
  language = {en},
  author = {Schulz, Stephan},
  pages = {17},
  file = {files/133/Schulz - E – A Brainiac Theorem Prover.pdf}
}

@article{shivajiReducingFeaturesImprove2013,
  title = {Reducing {{Features}} to {{Improve Code Change}}-{{Based Bug Prediction}}},
  volume = {39},
  issn = {0098-5589, 1939-3520},
  abstract = {Machine learning classifiers have recently emerged as a way to predict the introduction of bugs in changes made to source code files. The classifier is first trained on software history, and then used to predict if an impending change causes a bug. Drawbacks of existing classifier-based bug prediction techniques are insufficient performance for practical use and slow prediction times due to a large number of machine learned features. This paper investigates multiple feature selection techniques that are generally applicable to classification-based bug prediction methods. The techniques discard less important features until optimal classification performance is reached. The total number of features used for training is substantially reduced, often to less than 10 percent of the original. The performance of Naive Bayes and Support Vector Machine (SVM) classifiers when using this technique is characterized on 11 software projects. Naive Bayes using feature selection provides significant improvement in buggy F-measure (21 percent improvement) over prior change classification bug prediction results (by the second and fourth authors [28]). The SVM's improvement in buggy F-measure is 9 percent. Interestingly, an analysis of performance for varying numbers of features shows that strong performance is achieved at even 1 percent of the original number of features.},
  language = {en},
  number = {4},
  journal = {IIEEE Trans. Software Eng.},
  doi = {10.1109/TSE.2012.43},
  author = {Shivaji, S. and Whitehead, E. James and Akella, R. and {Sunghun Kim}},
  month = apr,
  year = {2013},
  pages = {552-569},
  file = {files/135/Shivaji et al. - 2013 - Reducing Features to Improve Code Change-Based Bug.pdf}
}

@inproceedings{halpernLogicReasoningUpper2001,
  title = {A {{Logic}} for {{Reasoning}} about {{Upper Probabilities}}},
  booktitle = {{{UAI}} '01: {{Proceedings}} of the 17th {{Conference}} in {{Uncertainty}} in {{Artificial Intelligence}}, {{University}} of {{Washington}}, {{Seattle}}, {{Washington}}, {{USA}}, {{August}} 2-5, 2001},
  author = {Halpern, Joseph Y. and Pucella, Riccardo},
  year = {2001},
  pages = {203--210}
}

@book{breeseUAI01Proceedings2001,
  title = {{{UAI}} '01: {{Proceedings}} of the 17th {{Conference}} in {{Uncertainty}} in {{Artificial Intelligence}}, {{University}} of {{Washington}}, {{Seattle}}, {{Washington}}, {{USA}}, {{August}} 2-5, 2001},
  isbn = {1-55860-800-1},
  publisher = {{Morgan Kaufmann}},
  editor = {Breese, Jack S. and Koller, Daphne},
  year = {2001},
  file = {files/139/1301.2279.pdf}
}

@article{grabowskiMizarNutshell2010,
  title = {Mizar in a {{Nutshell}}},
  volume = {3},
  number = {2},
  journal = {J. Formalized Reasoning},
  doi = {10.6092/issn.1972-5787/1980},
  author = {Grabowski, Adam and Kornilowicz, Artur and Naumowicz, Adam},
  year = {2010},
  pages = {153--245},
  file = {files/141/b9cf6eda3345ba43d2d86da3e4e646193088.pdf}
}

@article{bibalInterpretabilityMachineLearning2016,
  title = {Interpretability of {{Machine Learning Models}} and {{Representations}}: An {{Introduction}}},
  abstract = {Interpretability is often a major concern in machine learning. Although many authors agree with this statement, interpretability is often tackled with intuitive arguments, distinct (yet related) terms and heuristic quantifications. This short survey aims to clarify the concepts related to interpretability and emphasises the distinction between interpreting models and representations, as well as heuristic-based and user-based approaches.},
  language = {en},
  journal = {Computational Intelligence},
  author = {Bibal, Adrien and Fr{\'e}nay, Beno{\^i}t},
  year = {2016},
  pages = {6},
  file = {files/143/Bibal and Frénay - 2016 - Interpretability of Machine Learning Models and Re.pdf}
}

@article{clarkeFormalMethodsState1996,
  title = {Formal Methods: State of the Art and Future Directions},
  volume = {28},
  issn = {03600300},
  shorttitle = {Formal Methods},
  abstract = {VDM model was developed in conjunction with concrete user interface de nitions, semi-formal de nitions of the concurrent behavior, and de nitions of external interfaces. During design, the abstract VDM was re ned into more concrete module speci cations. At a lower level, the software for the dual LAN was speci ed and developed formally using CCS.},
  language = {en},
  number = {4},
  journal = {ACM Comput. Surv.},
  doi = {10.1145/242223.242257},
  author = {Clarke, Edmund M. and Wing, Jeannette M.},
  month = dec,
  year = {1996},
  pages = {626-643},
  file = {files/145/Clarke and Wing - 1996 - Formal methods state of the art and future direct.pdf}
}

@article{kitchenhamGuidelinesPerformingSystematic,
  title = {Guidelines for Performing {{Systematic Literature Reviews}} in {{Software Engineering}}},
  language = {en},
  author = {Kitchenham, Barbara},
  pages = {44},
  file = {files/149/Kitchenham - Guidelines for performing Systematic Literature Re.pdf}
}

@article{leyton-brownPortfolioApproachAlgorithm,
  title = {A {{Portfolio Approach}} to {{Algorithm Selection}}},
  language = {en},
  author = {{Leyton-Brown}, Kevin and Nudelman, Eugene and Andrew, Galen and McFadden, Jim and Shoham, Yoav},
  pages = {2},
  file = {files/151/Leyton-Brown et al. - A Portfolio Approach to Algorithm Selection.pdf}
}

@book{mitchellMachineLearning1997,
  address = {{New York}},
  series = {{{McGraw}}-{{Hill}} Series in Computer Science},
  title = {Machine {{Learning}}},
  isbn = {978-0-07-042807-2},
  lccn = {Q325.5 .M58 1997},
  language = {en},
  publisher = {{McGraw-Hill}},
  author = {Mitchell, Tom M.},
  year = {1997},
  keywords = {Computer algorithms,Machine learning},
  file = {files/153/Mitchell - 1997 - Machine Learning.pdf}
}

@inproceedings{lubyOptimalSpeedupVegas1993,
  title = {Optimal {{Speedup}} of {{Las Vegas Algorithms}}},
  booktitle = {Second {{Israel Symposium}} on {{Theory}} of {{Computing Systems}}, {{ISTCS}} 1993, {{Natanya}}, {{Israel}}, {{June}} 7-9, 1993, {{Proceedings}}},
  doi = {10.1109/ISTCS.1993.253477},
  author = {Luby, Michael and Sinclair, Alistair and Zuckerman, David},
  year = {1993},
  pages = {128--133},
  file = {files/159/main.pdf}
}

@book{SecondIsraelSymposium1993,
  title = {Second {{Israel Symposium}} on {{Theory}} of {{Computing Systems}}, {{ISTCS}} 1993, {{Natanya}}, {{Israel}}, {{June}} 7-9, 1993, {{Proceedings}}},
  isbn = {0-8186-3630-0},
  publisher = {{IEEE Computer Society}},
  year = {1993}
}

@incollection{frankWEKAMachineLearning2005,
  title = {{{WEKA}} - {{A Machine Learning Workbench}} for {{Data Mining}}},
  booktitle = {The {{Data Mining}} and {{Knowledge Discovery Handbook}}.},
  author = {Frank, Eibe and Hall, Mark A. and Holmes, Geoffrey and Kirkby, Richard and Pfahringer, Bernhard},
  year = {2005},
  pages = {1305--1314},
  file = {files/162/Witten_et_al_2016_appendix.pdf}
}

@book{maimonDataMiningKnowledge2005,
  title = {The {{Data Mining}} and {{Knowledge Discovery Handbook}}},
  isbn = {0-387-24435-2},
  publisher = {{Springer}},
  editor = {Maimon, Oded and Rokach, Lior},
  year = {2005}
}

@article{healyPredictingSMTSolver2017,
  title = {Predicting {{SMT Solver Performance}} for {{Software Verification}}},
  volume = {240},
  issn = {2075-2180},
  language = {en},
  journal = {Electron. Proc. Theor. Comput. Sci.},
  doi = {10.4204/EPTCS.240.2},
  author = {Healy, Andrew and Monahan, Rosemary and Power, James F.},
  month = jan,
  year = {2017},
  pages = {20-37},
  file = {files/177/Healy et al. - 2017 - Predicting SMT Solver Performance for Software Ver.pdf}
}

@inproceedings{liangLearningRateBased2016,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Learning {{Rate Based Branching Heuristic}} for {{SAT Solvers}}},
  isbn = {978-3-319-40970-2},
  abstract = {In this paper, we propose a framework for viewing solver branching heuristics as optimization algorithms where the objective is to maximize the learning rate, defined as the propensity for variables to generate learnt clauses. By viewing online variable selection in SAT solvers as an optimization problem, we can leverage a wide variety of optimization algorithms, especially from machine learning, to design effective branching heuristics. In particular, we model the variable selection optimization problem as an online multi-armed bandit, a special-case of reinforcement learning, to learn branching variables such that the learning rate of the solver is maximized. We develop a branching heuristic that we call learning rate branching or LRB, based on a well-known multi-armed bandit algorithm called exponential recency weighted average and implement it as part of MiniSat and CryptoMiniSat. We upgrade the LRB technique with two additional novel ideas to improve the learning rate by accounting for reason side rate and exploiting locality. The resulting LRB branching heuristic is shown to be faster than the VSIDS and conflict history-based (CHB) branching heuristics on 1975 application and hard combinatorial instances from 2009 to 2014 SAT Competitions. We also show that CryptoMiniSat with LRB solves more instances than the one with VSIDS. These experiments show that LRB improves on state-of-the-art.},
  language = {en},
  booktitle = {Theory and {{Applications}} of {{Satisfiability Testing}} \textendash{} {{SAT}} 2016},
  publisher = {{Springer International Publishing}},
  author = {Liang, Jia Hui and Ganesh, Vijay and Poupart, Pascal and Czarnecki, Krzysztof},
  editor = {Creignou, Nadia and Le Berre, Daniel},
  year = {2016},
  keywords = {CDCL Solver,Clause Learning,Implication Graph,Learning Rate,Slot Machine},
  pages = {123-140},
  file = {files/201/Liang et al. - 2016 - Learning Rate Based Branching Heuristic for SAT So.pdf}
}

@article{kongDeepNeuralNetwork2018,
  title = {A {{Deep Neural Network Model}} Using {{Random Forest}} to {{Extract Feature Representation}} for {{Gene Expression Data Classification}}},
  volume = {8},
  copyright = {2018 The Author(s)},
  issn = {2045-2322},
  abstract = {In predictive model development, gene expression data is associated with the unique challenge that the number of samples (n) is much smaller than the amount of features (p). This ``n\,{$\ll$}\,p'' property has prevented classification of gene expression data from deep learning techniques, which have been proved powerful under ``n\,{$>$}\,p'' scenarios in other application fields, such as image classification. Further, the sparsity of effective features with unknown correlation structures in gene expression profiles brings more challenges for classification tasks. To tackle these problems, we propose a newly developed classifier named Forest Deep Neural Network (fDNN), to integrate the deep neural network architecture with a supervised forest feature detector. Using this built-in feature detector, the method is able to learn sparse feature representations and feed the representations into a neural network to mitigate the overfitting problem. Simulation experiments and real data analyses using two RNA-seq expression datasets are conducted to evaluate fDNN's capability. The method is demonstrated a useful addition to current predictive models with better classification performance and more meaningful selected features compared to ordinary random forests and deep neural networks.},
  language = {En},
  number = {1},
  journal = {Scientific Reports},
  doi = {10.1038/s41598-018-34833-6},
  author = {Kong, Yunchuan and Yu, Tianwei},
  month = nov,
  year = {2018},
  pages = {16477},
  file = {files/203/Kong and Yu - 2018 - A Deep Neural Network Model using Random Forest to.pdf;files/204/s41598-018-34833-6.html}
}

@book{chawlaProceedings2017SIAM2017,
  address = {{Philadelphia, PA}},
  title = {Proceedings of the 2017 {{SIAM International Conference}} on {{Data Mining}}},
  isbn = {978-1-61197-497-3},
  abstract = {Neural networks have become very popular in recent years because of the astonishing success of deep learning in various domains such as image and speech recognition. In many of these domains, specific architectures of neural networks, such as convolutional networks, seem to fit the particular structure of the problem domain very well, and can therefore perform in an astonishingly effective way. However, the success of neural networks is not universal across all domains. Indeed, for learning problems without any special structure, or in cases where the data is somewhat limited, neural networks are known not to perform well with respect to traditional machine learning methods such as random forests. In this paper, we show that a carefully designed neural network with random forest structure can have better generalization ability. In fact, this architecture is more powerful than random forests, because the back-propagation algorithm reduces to a more powerful and generalized way of constructing a decision tree. Furthermore, the approach is efficient to train and requires a small constant factor of the number of training examples. This efficiency allows the training of multiple neural networks in order to improve the generalization accuracy. Experimental results on 10 realworld benchmark datasets demonstrate the effectiveness of the proposed enhancements.},
  language = {en},
  publisher = {{Society for Industrial and Applied Mathematics}},
  editor = {Chawla, Nitesh and Wang, Wei},
  month = jun,
  year = {2017},
  file = {files/205/Chawla and Wang - 2017 - Proceedings of the 2017 SIAM International Confere.pdf},
  doi = {10.1137/1.9781611974973}
}

@incollection{blomStateSpaceReduction2002,
  address = {{Berlin, Heidelberg}},
  title = {State {{Space Reduction}} by {{Proving Confluence}}},
  volume = {2404},
  isbn = {978-3-540-43997-4 978-3-540-45657-5},
  abstract = {We present a modular method for on-the-fly state space reduction. The theoretical foundation of the method is a new confluence notion for labeled transition systems. The method works by adding confluence information to the symbolic representation of the state space. We present algorithms for on-the-fly exploration of the reduced state space, for detection of confluence properties and for a symbolic reduction, called prioritization. The latter two algorithms rely on an automated theorem prover to derive the necessary information. We also present some case studies in which tools that implement these algorithms were used.},
  language = {en},
  booktitle = {Computer {{Aided Verification}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Blom, Stefan and {van de Pol}, Jaco},
  editor = {Goos, Gerhard and Hartmanis, Juris and {van Leeuwen}, Jan and Brinksma, Ed and Larsen, Kim Guldstrand},
  year = {2002},
  pages = {596-609},
  file = {files/207/Blom and van de Pol - 2002 - State Space Reduction by Proving Confluence.pdf},
  doi = {10.1007/3-540-45657-0\_50}
}

@misc{henzingerModelCheckingTheorem,
  title = {Model {{Checking}}, {{Theorem Proving}}, and {{Abstract Interpretation}}:},
  language = {en},
  author = {Henzinger, Tom},
  file = {files/209/Henzinger - Model Checking, Theorem Proving, and Abstract Inte.pdf}
}

@incollection{bultanStateSpaceExploration2017,
  address = {{Cham}},
  title = {State {{Space Exploration}}},
  isbn = {978-3-319-68670-7},
  abstract = {In this chapter we provide a basic survey of reachability analysis for verification of string manipulating programs starting with explicit state enumeration. We discuss both forward and backward reachability analysis using depth-first search where states of a given string manipulating program are traversed one state at a time. Next, we discuss symbolic reachability analysis, where the basic idea is to perform state exploration using sets of states rather than traversing states one by one. We discuss that reachability analysis corresponds to fixpoint computations, and, in order to develop a symbolic analysis framework for string manipulating programs, we need to first develop a symbolic representation that can represent sets of strings.},
  language = {en},
  booktitle = {String {{Analysis}} for {{Software Verification}} and {{Security}}},
  publisher = {{Springer International Publishing}},
  author = {Bultan, Tevfik and Yu, Fang and Alkhalaf, Muath and Aydin, Abdulbaki},
  editor = {Bultan, Tevfik and Yu, Fang and Alkhalaf, Muath and Aydin, Abdulbaki},
  year = {2017},
  pages = {23-35},
  file = {files/214/Bultan et al. - 2017 - State Space Exploration.pdf},
  doi = {10.1007/978-3-319-68670-7\_3}
}

@article{tangExplorationStudyCountBased,
  title = {\#{{Exploration}}: {{A Study}} of {{Count}}-{{Based Exploration}} for {{Deep Reinforcement Learning}}},
  abstract = {Count-based exploration algorithms are known to perform near-optimally when used in conjunction with tabular reinforcement learning (RL) methods for solving small discrete Markov decision processes (MDPs). It is generally thought that count-based methods cannot be applied in high-dimensional state spaces, since most states will only occur once. Recent deep RL exploration strategies are able to deal with high-dimensional continuous state spaces through complex heuristics, often relying on optimism in the face of uncertainty or intrinsic motivation. In this work, we describe a surprising finding: a simple generalization of the classic count-based approach can reach near state-of-the-art performance on various highdimensional and/or continuous deep RL benchmarks. States are mapped to hash codes, which allows to count their occurrences with a hash table. These counts are then used to compute a reward bonus according to the classic count-based exploration theory. We find that simple hash functions can achieve surprisingly good results on many challenging tasks. Furthermore, we show that a domaindependent learned hash code may further improve these results. Detailed analysis reveals important aspects of a good hash function: 1) having appropriate granularity and 2) encoding information relevant to solving the MDP. This exploration strategy achieves near state-of-the-art performance on both continuous control tasks and Atari 2600 games, hence providing a simple yet powerful baseline for solving MDPs that require considerable exploration.},
  language = {en},
  author = {Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, OpenAI Xi and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
  pages = {10},
  file = {files/219/Tang et al. - #Exploration A Study of Count-Based Exploration f.pdf}
}

@article{thrunCientExplorationReinforcement,
  title = {E Cient {{Exploration In Reinforcement Learning}}},
  abstract = {Exploration plays a fundamental role in any active learning system. This study evaluates the role of exploration in active learning and describes several local techniques for exploration in nite, discrete domains, embedded in a reinforcement learning framework (delayed reinforcement).},
  language = {en},
  author = {Thrun, Sebastian B},
  pages = {44},
  file = {files/224/Thrun - E cient Exploration In Reinforcement Learning.pdf}
}

@article{irvingDeepMathDeepSequence,
  title = {{{DeepMath}} - {{Deep Sequence Models}} for {{Premise Selection}}},
  abstract = {We study the effectiveness of neural sequence models for premise selection in automated theorem proving, one of the main bottlenecks in the formalization of mathematics. We propose a two stage approach for this task that yields good results for the premise selection task on the Mizar corpus while avoiding the handengineered features of existing state-of-the-art models. To our knowledge, this is the first time deep learning has been applied to theorem proving on a large scale.},
  language = {en},
  author = {Irving, Geoffrey and Szegedy, Christian and Alemi, Alexander A and Een, Niklas and Chollet, Francois and Urban, Josef},
  pages = {9},
  file = {files/227/Irving et al. - DeepMath - Deep Sequence Models for Premise Select.pdf}
}

@article{guidottiSurveyMethodsExplaining2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1802.01933},
  primaryClass = {cs},
  title = {A {{Survey Of Methods For Explaining Black Box Models}}},
  abstract = {In the last years many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness sometimes at the cost of scarifying accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, delineating explicitly or implicitly its own definition of interpretability and explanation. The aim of this paper is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
  language = {en},
  journal = {arXiv:1802.01933 [cs]},
  author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Pedreschi, Dino and Giannotti, Fosca},
  month = feb,
  year = {2018},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Computers and Society},
  file = {files/231/Guidotti et al. - 2018 - A Survey Of Methods For Explaining Black Box Model.pdf}
}

@incollection{farberMonteCarloTableau2017,
  address = {{Cham}},
  title = {Monte {{Carlo Tableau Proof Search}}},
  volume = {10395},
  isbn = {978-3-319-63045-8 978-3-319-63046-5},
  abstract = {We study Monte Carlo Tree Search to guide proof search in tableau calculi. This includes proposing a number of proof-state evaluation heuristics, some of which are learnt from previous proofs. We present an implementation based on the leanCoP prover. The system is trained and evaluated on a large suite of related problems coming from the Mizar proof assistant, showing that it is capable to find new and different proofs.},
  language = {en},
  booktitle = {Automated {{Deduction}} \textendash{} {{CADE}} 26},
  publisher = {{Springer International Publishing}},
  author = {F{\"a}rber, Michael and Kaliszyk, Cezary and Urban, Josef},
  editor = {{de Moura}, Leonardo},
  year = {2017},
  pages = {563-579},
  file = {files/235/Färber et al. - 2017 - Monte Carlo Tableau Proof Search.pdf},
  doi = {10.1007/978-3-319-63046-5\_34}
}

@incollection{kocsisBanditBasedMonteCarlo2006,
  address = {{Berlin, Heidelberg}},
  title = {Bandit {{Based Monte}}-{{Carlo Planning}}},
  volume = {4212},
  isbn = {978-3-540-45375-8 978-3-540-46056-5},
  abstract = {For large state-space Markovian Decision Problems MonteCarlo planning is one of the few viable approaches to find near-optimal solutions. In this paper we introduce a new algorithm, UCT, that applies bandit ideas to guide Monte-Carlo planning. In finite-horizon or discounted MDPs the algorithm is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling. Experimental results show that in several domains, UCT is significantly more efficient than its alternatives.},
  language = {en},
  booktitle = {Machine {{Learning}}: {{ECML}} 2006},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Kocsis, Levente and Szepesv{\'a}ri, Csaba},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and F{\"u}rnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
  year = {2006},
  pages = {282-293},
  file = {files/237/Kocsis and Szepesvári - 2006 - Bandit Based Monte-Carlo Planning.pdf},
  doi = {10.1007/11871842\_29}
}

@inproceedings{ramirezOptimizingSMTSolving2018,
  title = {Optimizing {{SMT Solving Strategies}} by {{Learning}} with an {{Evolutionary Process}}},
  abstract = {This paper deals with program optimization, i.e., learning of more efficient programs. The programs we want to improve are Z3 solving strategies. Z3 is a SMT (SAT Modulo Theory) solver which is currently developed by Microsoft Research. We define strategy generators based on evolutionary processes. SMT solving strategies include various aspects that can affect the performance of a SMT solver dramatically. Each of these elements includes a huge amount of options which cannot be exploited without expert knowledge. We define a generic evolutionary algorithm based on genetic programming concepts. This strategy generation process aims at learning better strategies by successive improvements, using rules that can be combined in order to handle both structures and parameters of the strategies. We experiment 7 different strategies generators on 2 SMT logics (QF\_LRA,QF\_LIA). The results show that the learned strategies improve default strategies available in the solver.},
  booktitle = {2018 {{International Conference}} on {{High Performance Computing Simulation}} ({{HPCS}})},
  doi = {10.1109/HPCS.2018.00132},
  author = {Ram{\'i}rez, N. G. and Monfroy, E. and Saubion, F. and Castro, C.},
  month = jul,
  year = {2018},
  keywords = {computability,Evolutionary computation,evolutionary process,Generators,generic evolutionary algorithm,genetic algorithms,Genetic programming,genetic programming concepts,learned strategies,learning (artificial intelligence),Optimization,Probes,program optimization,SAT Modulo Theory,SMT logics,SMT solver,SMT solving strategies,Sociology,Statistics,strategy generation process,strategy generators,Z3 solving strategies},
  pages = {816-820},
  file = {files/242/Ramírez et al. - 2018 - Optimizing SMT Solving Strategies by Learning with.pdf;files/244/8514437.html}
}

@inproceedings{monniauxSurveySatisfiabilityModulo2016,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {A {{Survey}} of {{Satisfiability Modulo Theory}}},
  isbn = {978-3-319-45641-6},
  abstract = {Satisfiability modulo theory (SMT) consists in testing the satisfiability of first-order formulas over linear integer or real arithmetic, or other theories. In this survey, we explain the combination of propositional satisfiability and decision procedures for conjunctions known as DPLL(T), and the alternative ``natural domain'' approaches. We also cover quantifiers, Craig interpolants, polynomial arithmetic, and how SMT solvers are used in automated software analysis.},
  language = {en},
  booktitle = {Computer {{Algebra}} in {{Scientific Computing}}},
  publisher = {{Springer International Publishing}},
  author = {Monniaux, David},
  editor = {Gerdt, Vladimir P. and Koepf, Wolfram and Seiler, Werner M. and Vorozhtsov, Evgenii V.},
  year = {2016},
  keywords = {Conjunctive Normal Form,Quantifier Elimination,Satisfiability Modulo Theory,Satisfying Assignment,Symbolic Execution},
  pages = {401-425},
  file = {files/245/Monniaux - 2016 - A Survey of Satisfiability Modulo Theory.pdf}
}

@inproceedings{ernstVerifyThisVerificationCompetition2019,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {{{VerifyThis}} \textendash{} {{Verification Competition}} with a {{Human Factor}}},
  isbn = {978-3-030-17502-3},
  abstract = {VerifyThis is a series of competitions that aims to evaluate the current state of deductive tools to prove functional correctness of programs. Such proofs typically require human creativity, and hence it is not possible to measure the performance of tools independently of the skills of its user. Similarly, solutions can be judged by humans only. In this paper, we discuss the role of the human in the competition setup and explore possible future changes to the current format. Regarding the impact of VerifyThis on deductive verification research, a survey conducted among the previous participants shows that the event is a key enabler for gaining insight into other approaches, and that it fosters collaboration and exchange.},
  language = {en},
  booktitle = {Tools and {{Algorithms}} for the {{Construction}} and {{Analysis}} of {{Systems}}},
  publisher = {{Springer International Publishing}},
  author = {Ernst, Gidon and Huisman, Marieke and Mostowski, Wojciech and Ulbrich, Mattias},
  editor = {Beyer, Dirk and Huisman, Marieke and Kordon, Fabrice and Steffen, Bernhard},
  year = {2019},
  keywords = {Competition,Program verification,Specification languages,Tool development,VerifyThis},
  pages = {176-195},
  file = {files/255/Ernst et al. - 2019 - VerifyThis – Verification Competition with a Human.pdf}
}

@book{eibenIntroductionEvolutionaryComputing2015,
  edition = {2nd},
  title = {Introduction to {{Evolutionary Computing}}},
  isbn = {978-3-662-44873-1},
  abstract = {The overall structure of this new edition is three-tier: Part I presents the basics, Part II is concerned with methodological issues, and Part III discusses advanced topics. In the second edition the authors have reorganized the material to focus on problems, how to represent them, and then how to choose and design algorithms for different representations. They also added a chapter on problems, reflecting the overall book focus on problem-solvers, a chapter on parameter tuning, which they combined with the parameter control and "how-to" chapters into a methodological part, and finally a chapter on evolutionary robotics with an outlook on possible exciting developments in this field. The book is suitable for undergraduate and graduate courses in artificial intelligence and computational intelligence, and for self-study by practitioners and researchers engaged with all aspects of bioinspired design and optimization.},
  publisher = {{Springer Publishing Company, Incorporated}},
  author = {Eiben, A. E. and Smith, James E.},
  year = {2015}
}

@book{mitchellIntroductionGeneticAlgorithms1998,
  address = {{Cambridge, MA, USA}},
  title = {An {{Introduction}} to {{Genetic Algorithms}}},
  isbn = {978-0-262-63185-3},
  abstract = {From the Publisher: "This is the best general book on Genetic Algorithms written to date. It covers background, history, and motivation; it selects important, informative examples of applications and discusses the use of Genetic Algorithms in scientific models; and it gives a good account of the status of the theory of Genetic Algorithms. Best of all the book presents its material in clear, straightforward, felicitous prose, accessible to anyone with a college-level scientific background. If you want a broad, solid understanding of Genetic Algorithms -- where they came from, what's being done with them, and where they are going -- this is the book. -- John H. Holland, Professor, Computer Science and Engineering, and Professor of Psychology, The University of Michigan; External Professor, the Santa Fe Institute.  Genetic algorithms have been used in science and engineering as adaptive algorithms for solving practical problems and as computational models of natural evolutionary systems. This brief, accessible introduction describes some of the most interesting research in the field and also enables readers to implement and experiment with genetic algorithms on their own. It focuses in depth on a small set of important and interesting topics -- particularly in machine learning, scientific modeling, and artificial life -- and reviews a broad span of research, including the work of Mitchell and her colleagues.  The descriptions of applications and modeling projects stretch beyond the strict boundaries of computer science to include dynamical systems theory, game theory, molecular biology, ecology, evolutionary biology, and population genetics, underscoring the exciting "general purpose" nature of genetic algorithms as search methods that can be employed across disciplines. An Introduction to Genetic Algorithms is accessible to students and researchers in any scientific discipline. It includes many thought and computer exercises that build on and reinforce the reader's understanding of the text.  The first chapter introduces genetic algorithms and their terminology and describes two provocative applications in detail. The second and third chapters look at the use of genetic algorithms in machine learning (computer programs, data analysis and prediction, neural networks) and in scientific models (interactions among learning, evolution, and culture; sexual selection; ecosystems; evolutionary activity). Several approaches to the theory of genetic algorithms are discussed in depth in the fourth chapter. The fifth chapter takes up implementation, and the last chapter poses some currently unanswered questions and surveys prospects for the future of evolutionary computation.},
  publisher = {{MIT Press}},
  author = {Mitchell, Melanie},
  year = {1998},
  file = {files/266/Melanie - An Introduction to Genetic Algorithms.pdf}
}

@misc{theboeingcompanyBoeing737MAX,
  title = {Boeing: {{The}} 737 {{MAX MCAS Software Enhancement}}},
  shorttitle = {Boeing},
  abstract = {737 MAX \textendash{} MCAS Software Update. What is a Maneuvering Characteristics Augmentation System (MCAS) and how are pilots trained on it? Offical Boeing page.},
  language = {en},
  journal = {Boeing: The 737 MAX MCAS Software Enhancement},
  howpublished = {https://www.boeing.com/commercial/737max/737-max-software-updates.page},
  author = {{The Boeing Company}},
  file = {files/272/737-max-software-updates.html}
}

@book{baeckHandbookEvolutionaryComputation1997,
  title = {Handbook of {{Evolutionary Computation}}},
  isbn = {978-1-4200-5038-7},
  abstract = {Many scientists and engineers now use the paradigms of evolutionary computation (genetic algorithms, evolution strategies, evolutionary programming, genetic},
  language = {en},
  publisher = {{CRC Press}},
  author = {Baeck, Thomas and Fogel, D. B. and Michalewicz, Z. and Fogel, D. B. and Michalewicz, Z.},
  month = jan,
  year = {1997},
  file = {files/285/9781420050387.html},
  doi = {10.1201/9781420050387}
}

@article{shemerPropertyDirectedSelf2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1905.07705},
  primaryClass = {cs},
  title = {Property {{Directed Self Composition}}},
  abstract = {We address the problem of verifying k-safety properties: properties that refer to k-interacting executions of a program. A prominent way to verify k-safety properties is by self composition. In this approach, the problem of checking k-safety over the original program is reduced to checking an "ordinary" safety property over a program that executes k copies of the original program in some order. The way in which the copies are composed determines how complicated it is to verify the composed program. We view this composition as provided by a semantic self composition function that maps each state of the composed program to the copies that make a move. Since the "quality" of a self composition function is measured by the ability to verify the safety of the composed program, we formulate the problem of inferring a self composition function together with the inductive invariant needed to verify safety of the composed program, where both are restricted to a given language. We develop a property-directed inference algorithm that, given a set of predicates, infers composition-invariant pairs expressed by Boolean combinations of the given predicates, or determines that no such pair exists. We implemented our algorithm and demonstrate that it is able to find self compositions that are beyond reach of existing tools.},
  journal = {arXiv:1905.07705 [cs]},
  author = {Shemer, Ron and Gurfinkel, Arie and Shoham, Sharon and Vizel, Yakir},
  month = may,
  year = {2019},
  keywords = {Computer Science - Programming Languages},
  file = {files/293/Shemer et al. - 2019 - Property Directed Self Composition.pdf;files/292/1905.html}
}

@inproceedings{hutterPerformancePredictionAutomated2006,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Performance {{Prediction}} and {{Automated Tuning}} of {{Randomized}} and {{Parametric Algorithms}}},
  isbn = {978-3-540-46268-2},
  abstract = {Machine learning can be used to build models that predict the run-time of search algorithms for hard combinatorial problems. Such empirical hardness models have previously been studied for complete, deterministic search algorithms. In this work, we demonstrate that such models can also make surprisingly accurate predictions of the run-time distributions of incomplete and randomized search methods, such as stochastic local search algorithms. We also show for the first time how information about an algorithm's parameter settings can be incorporated into a model, and how such models can be used to automatically adjust the algorithm's parameters on a per-instance basis in order to optimize its performance. Empirical results for Novelty + and SAPS on structured and unstructured SAT instances show very good predictive performance and significant speedups of our automatically determined parameter settings when compared to the default and best fixed distribution-specific parameter settings.},
  language = {en},
  booktitle = {Principles and {{Practice}} of {{Constraint Programming}} - {{CP}} 2006},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Hutter, Frank and Hamadi, Youssef and Hoos, Holger H. and {Leyton-Brown}, Kevin},
  editor = {Benhamou, Fr{\'e}d{\'e}ric},
  year = {2006},
  keywords = {Gaussian Process Regression,Hard Instance,Local Search,Root Mean Square Error,Stochastic Local Search},
  pages = {213-228},
  file = {files/299/Hutter et al. - 2006 - Performance Prediction and Automated Tuning of Ran.pdf}
}

@inproceedings{wuImprovingSATsolvingMachine2017,
  address = {{New York, NY, USA}},
  series = {{{SIGCSE}} '17},
  title = {Improving {{SAT}}-Solving with {{Machine Learning}}},
  isbn = {978-1-4503-4698-6},
  abstract = {In this project, we aimed to improve the runtime of Minisat, a Conflict-Driven Clause Learning (CDCL) solver that solves the Propositional Boolean Satisfiability (SAT) problem. We first used a logistic regression model to predict the satisfiability of propositional boolean formulae after fixing the values of a certain fraction of the variables in each formula. We then applied the logistic model and added a preprocessing period to Minisat to determine the preferable initial value (either true or false) of each boolean variable using a Monte-Carlo approach. Concretely, for each Monte-Carlo trial, we fixed the values of a certain ratio of randomly selected variables, and calculated the confidence that the resulting sub-formula is satisfiable with our logistic regression model. The initial value of each variable was set based on the mean confidence scores of the trials that started from the literals of that variable. We were particularly interested in setting the initial values of the backbone variables correctly, which are variables that have the same value in all solutions of a SAT formula. Our Monte-Carlo method was able to set 78\% of the backbones correctly. Excluding the preprocessing time, compared with the default setting of Minisat, the runtime of Minisat for satisfiable formulae decreased by 23\%. However, our method did not outperform vanilla Minisat in runtime, as the decrease in the conflicts was outweighed by the long runtime of the preprocessing period.},
  booktitle = {Proceedings of the 2017 {{ACM SIGCSE Technical Symposium}} on {{Computer Science Education}}},
  publisher = {{ACM}},
  doi = {10.1145/3017680.3022464},
  author = {Wu, Haoze},
  year = {2017},
  keywords = {machine learning,3SAT,logistic,monte-carlo,satisfiability},
  pages = {787--788},
  file = {files/301/Wu - 2017 - Improving SAT-solving with Machine Learning.pdf}
}

@inproceedings{clarkeSATBasedAbstractionRefinement2002,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {{{SAT Based Abstraction}}-{{Refinement Using ILP}} and {{Machine Learning Techniques}}},
  isbn = {978-3-540-45657-5},
  abstract = {We describe new techniques for model checking in the counterexample guided abstraction/refinement framework. The abstraction phase `hides' the logic of various variables, hence considering them as inputs. This type of abstraction may lead to `spurious' counterexamples, i.e. traces that can not be simulated on the original (concrete) machine. We check whether a counterexample is real or spurious with a SAT checker. We then use a combination of Integer Linear Programming (ILP) and machine learning techniques for refining the abstraction based on the counterexample. The process is repeated until either a real counterexample is found or the property is verified. We have implemented these techniques on top of the model checker NuSMV and the SAT solver Chaff. Experimental results prove the viability of these new techniques.},
  language = {en},
  booktitle = {Computer {{Aided Verification}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Clarke, Edmund and Gupta, Anubhav and Kukula, James and Strichman, Ofer},
  editor = {Brinksma, Ed and Larsen, Kim Guldstrand},
  year = {2002},
  keywords = {Concrete System,Integer Linear Program,Integer Linear Program Problem,Model Check,Visible Variable},
  pages = {265-279},
  file = {files/303/Clarke et al. - 2002 - SAT Based Abstraction-Refinement Using ILP and Mac.pdf}
}

@article{kimClassifyingSoftwareChanges2008,
  title = {Classifying {{Software Changes}}: {{Clean}} or {{Buggy}}?},
  volume = {34},
  issn = {0098-5589},
  shorttitle = {Classifying {{Software Changes}}},
  abstract = {This paper introduces a new technique for predicting latent software bugs, called change classification. Change classification uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes or clean changes. In this manner, change classification predicts the existence of bugs in software changes. The classifier is trained using features (in the machine learning sense) extracted from the revision history of a software project stored in its software configuration management repository. The trained classifier can classify changes as buggy or clean, with a 78 percent accuracy and a 60 percent buggy change recall on average. Change classification has several desirable qualities: 1) The prediction granularity is small (a change to a single file), 2) predictions do not require semantic information about the source code, 3) the technique works for a broad array of project types and programming languages, and 4) predictions can be made immediately upon the completion of a change. Contributions of this paper include a description of the change classification approach, techniques for extracting features from the source code and change histories, a characterization of the performance of change classification across 12 open source projects, and an evaluation of the predictive power of different groups of features.},
  number = {2},
  journal = {IEEE Transactions on Software Engineering},
  doi = {10.1109/TSE.2007.70773},
  author = {Kim, S. and Jr, E. J. Whitehead and Zhang, Y.},
  month = mar,
  year = {2008},
  keywords = {Machine learning,learning (artificial intelligence),History,data mining,Data mining,and association rules,association rule,change classification,classification,Classification algorithms,Clustering,Computer bugs,Computer languages,Configuration Management,feature extraction,Feature extraction,machine learning classifier,Metrics/Measurement,open source projects,Open source software,program debugging,programming languages,Project management,software change,software configuration management repository,Software debugging,software maintenance,Software maintenance,software metrics,software project},
  pages = {181-196},
  file = {files/305/Kim et al. - 2008 - Classifying Software Changes Clean or Buggy.pdf;files/306/4408585.html}
}

@article{yerimaAndroidMalwareDetection2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1607.08186},
  title = {Android {{Malware Detection Using Parallel Machine Learning Classifiers}}},
  abstract = {Mobile malware has continued to grow at an alarming rate despite on-going efforts towards mitigating the problem. This has been particularly noticeable on Android due to its being an open platform that has subsequently overtaken other platforms in the share of the mobile smart devices market. Hence, incentivizing a new wave of emerging Android malware sophisticated enough to evade most common detection methods. This paper proposes and investigates a parallel machine learning based classification approach for early detection of Android malware. Using real malware samples and benign applications, a composite classification model is developed from parallel combination of heterogeneous classifiers. The empirical evaluation of the model under different combination schemes demonstrates its efficacy and potential to improve detection accuracy. More importantly, by utilizing several classifiers with diverse characteristics, their strengths can be harnessed not only for enhanced Android malware detection but also quicker white box analysis by means of the more interpretable constituent classifiers.},
  journal = {2014 Eighth International Conference on Next Generation Mobile Apps, Services and Technologies},
  doi = {10.1109/NGMAST.2014.23},
  author = {Yerima, Suleiman Y. and Sezer, Sakir and Muttik, Igor},
  month = sep,
  year = {2014},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security},
  pages = {37-42},
  file = {files/309/Yerima et al. - 2014 - Android Malware Detection Using Parallel Machine L.pdf;files/310/1607.html}
}

@inproceedings{kuhlweinOverviewEvaluationPremise2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Overview and {{Evaluation}} of {{Premise Selection Techniques}} for {{Large Theory Mathematics}}},
  isbn = {978-3-642-31365-3},
  abstract = {In this paper, an overview of state-of-the-art techniques for premise selection in large theory mathematics is provided, and new premise selection techniques are introduced. Several evaluation metrics are introduced, compared and their appropriateness is discussed in the context of automated reasoning in large theory mathematics. The methods are evaluated on the MPTP2078 benchmark, a subset of the Mizar library, and a 10\% improvement is obtained over the best method so far.},
  language = {en},
  booktitle = {Automated {{Reasoning}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {K{\"u}hlwein, Daniel and {van Laarhoven}, Twan and Tsivtsivadze, Evgeni and Urban, Josef and Heskes, Tom},
  editor = {Gramlich, Bernhard and Miller, Dale and Sattler, Uli},
  year = {2012},
  keywords = {Automate Reasoning,Evaluation Metrics,Latent Semantic Analysis,Prediction Function,Random Projection},
  pages = {378-392},
  file = {files/312/Kühlwein et al. - 2012 - Overview and Evaluation of Premise Selection Techn.pdf}
}

@book{nipkowIsabelleHOLProof2002,
  address = {{Berlin ; New York}},
  series = {Lecture Notes in Computer Science},
  title = {Isabelle/{{HOL}}: A Proof Assistant for Higher-Order Logic},
  isbn = {978-3-540-43376-7},
  lccn = {QA76.9.L63 N55 2002},
  shorttitle = {Isabelle/{{HOL}}},
  language = {en},
  number = {2283},
  publisher = {{Springer}},
  author = {Nipkow, Tobias and Paulson, Lawrence C. and Wenzel, Markus},
  year = {2002},
  keywords = {Automatic theorem proving,Computer logic},
  file = {files/313/Nipkow et al. - 2002 - IsabelleHOL a proof assistant for higher-order l.pdf}
}

@misc{technischeuniversitatmunchenIsabelle,
  title = {Isabelle},
  language = {en},
  journal = {o},
  howpublished = {https://isabelle.in.tum.de/},
  author = {{Technische Universit{\"a}t M{\"u}nchen}},
  file = {files/318/isabelle.in.tum.de.html}
}

@inproceedings{filliatreWhy3WherePrograms2013,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Why3 \textemdash{} {{Where Programs Meet Provers}}},
  isbn = {978-3-642-37036-6},
  abstract = {We present Why3, a tool for deductive program verification, and WhyML, its programming and specification language. WhyML is a first-order language with polymorphic types, pattern matching, and inductive predicates. Programs can make use of record types with mutable fields, type invariants, and ghost code. Verification conditions are discharged by Why3 with the help of various existing automated and interactive theorem provers. To keep verification conditions tractable and comprehensible, WhyML imposes a static control of aliases that obviates the use of a memory model. A user can write WhyML programs directly and get correct-by-construction OCaml programs via an automated extraction mechanism. WhyML is also used as an intermediate language for the verification of C, Java, or Ada programs. We demonstrate the benefits of Why3 and WhyML on non-trivial examples of program verification.},
  language = {en},
  booktitle = {Programming {{Languages}} and {{Systems}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Filli{\^a}tre, Jean-Christophe and Paskevich, Andrei},
  editor = {Felleisen, Matthias and Gardner, Philippa},
  year = {2013},
  keywords = {Abstract Data Type,Intermediate Language,Polymorphic Type,Proof Obligation,Type Invariant},
  pages = {125-128},
  file = {files/321/Filliâtre and Paskevich - 2013 - Why3 — Where Programs Meet Provers.pdf}
}

@misc{inriaAltErgoTheoremProver,
  title = {The {{Alt}}-{{Ergo Theorem Prover}}: {{Academic Web Page}}},
  journal = {The Alt-Ergo Theorem Prover: Academic Web Page},
  howpublished = {http://alt-ergo.lri.fr/},
  author = {{Inria} and {LRI} and {CNRS} and {Universit{\'e} Paris Sud}},
  file = {files/323/alt-ergo.lri.fr.html}
}

@inproceedings{demouraZ3EfficientSMT2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Z3: {{An Efficient SMT Solver}}},
  isbn = {978-3-540-78800-3},
  shorttitle = {Z3},
  abstract = {Satisfiability Modulo Theories (SMT) problem is a decision problem for logical first order formulas with respect to combinations of background theories such as: arithmetic, bit-vectors, arrays, and uninterpreted functions. Z3 is a new and efficient SMT Solver freely available from Microsoft Research. It is used in various software verification and analysis applications.},
  language = {en},
  booktitle = {Tools and {{Algorithms}} for the {{Construction}} and {{Analysis}} of {{Systems}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {{de Moura}, Leonardo and Bj{\o}rner, Nikolaj},
  editor = {Ramakrishnan, C. R. and Rehof, Jakob},
  year = {2008},
  keywords = {Symbolic Execution,Bound Model Check,Linear Arithmetic,Predicate Abstraction,Theory Solver},
  pages = {337-340},
  file = {files/326/de Moura and Bjørner - 2008 - Z3 An Efficient SMT Solver.pdf}
}

@inproceedings{lounisIntegratingMachinelearningTechniques1993,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Integrating Machine-Learning Techniques in Knowledge-Based Systems Verification},
  isbn = {978-3-540-47750-1},
  abstract = {A significant problem in the development of Knowledge-Based Systems (KBS) is its verification step. This paper describes an expert system verification approach that considers system specifications, and consequently, Knowledge Bases (KB) to be partially described when development starts. This partial description is not necessarily perfect and our work aims at using Machine Learning techniques to progressively improve the quality of expert system Knowledge Bases. by coping with two major KB anomalies: incompleteness and incorrectness. In agreement with the current tendency, KBs considered in our approach are expressed in different formalisms. Results obtained with two different learning algorithms, confirm the hypothesis that integrating machine learning techniques in the verification step of a Knowledge-Based System life cycle, is a promising approach.},
  language = {en},
  booktitle = {Methodologies for {{Intelligent Systems}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Lounis, Hakim},
  editor = {Komorowski, Jan and Ra{\'s}, Zbigniew W.},
  year = {1993},
  keywords = {Formal Specifications,Integrity Constraint,Machine Learning,Production Rules,Revision Process,Semantic-Net,Verification},
  pages = {405-414},
  file = {files/328/Lounis - 1993 - Integrating machine-learning techniques in knowled.pdf}
}

@incollection{hahnleQuoVadisFormal2016,
  address = {{Cham}},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Quo {{Vadis Formal Verification}}?},
  isbn = {978-3-319-49812-6},
  abstract = {The KeY System has been developed for over a decade. During this time, the field of Formal Methods as well as Computer Science in general has changed considerably. Based on an analysis of this trajectory of changes we argue why, after all these years, the project is still relevant and what the challenges in the coming years might be. At the same time we give a brief overview of the various tools based on KeY technology and explain their architecture.},
  language = {en},
  booktitle = {Deductive {{Software Verification}} \textendash{} {{The KeY Book}}: {{From Theory}} to {{Practice}}},
  publisher = {{Springer International Publishing}},
  author = {H{\"a}hnle, Reiner},
  editor = {Ahrendt, Wolfgang and Beckert, Bernhard and Bubel, Richard and H{\"a}hnle, Reiner and Schmitt, Peter H. and Ulbrich, Mattias},
  year = {2016},
  keywords = {Symbolic Execution,Model Check,Proof Obligation,Object Constraint Language,Java Program},
  pages = {1-19},
  file = {files/363/Hähnle - 2016 - Quo Vadis Formal Verification.pdf},
  doi = {10.1007/978-3-319-49812-6\_1}
}

@incollection{beckertDynamicLogicJava2016a,
  address = {{Cham}},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Dynamic {{Logic}} for {{Java}}},
  isbn = {978-3-319-49812-6},
  abstract = {In this chapter, we introduce an instance of dynamic logic, called JavaDL, that allows us to reason about Java programs. Dynamic logic extends first-order logic and makes it possible to consider several program states in a single formula. Its principle is the formulation of assertions about program behavior by integrating programs and formulas within a single language. We present a sequent calculus for JavaDL, which is used in the KeY System for verifying Java programs. Deduction in this calculus is based on symbolic program execution and simple program transformations and is, thus, close to a programmer's understanding of Java. Besides rules for symbolic execution, the calculus contains rules for program abstraction and modularization, including invariant rules for reasoning about loops and rules that replace a method invocation by the method's contract.},
  language = {en},
  booktitle = {Deductive {{Software Verification}} \textendash{} {{The KeY Book}}: {{From Theory}} to {{Practice}}},
  publisher = {{Springer International Publishing}},
  author = {Beckert, Bernhard and Klebanov, Vladimir and Wei{\ss}, Benjamin},
  editor = {Ahrendt, Wolfgang and Beckert, Bernhard and Bubel, Richard and H{\"a}hnle, Reiner and Schmitt, Peter H. and Ulbrich, Mattias},
  year = {2016},
  keywords = {Symbolic Execution,Program Variable,Dynamic Logic,Java Program,Kripke Structure},
  pages = {49-106},
  file = {files/369/Beckert et al. - 2016 - Dynamic Logic for Java.pdf},
  doi = {10.1007/978-3-319-49812-6\_3}
}

@book{beckertTacletsNewParadigm,
  title = {Taclets: {{A New Paradigm}} for {{Constructing Interactive Theorem Provers}}},
  shorttitle = {Taclets},
  abstract = {Frameworks for interactive theorem proving give the user explicit control over the construction  of proofs based on meta languages that contain dedicated control structures for describing proof  construction. Such languages are not easy to master and thus contribute to the already long list of skills  required by prospective users of interactive theorem provers. Most users, however, only need a convenient  formalism that allows to introduce new rules with minimal overhead. On the the other hand, rules of  calculi have not only purely logical content, but contain restrictions on the expected context of rule applications  and heuristic information. We suggest a new and minimalist concept for implementing interactive  theorem provers called taclet. Their usage can be mastered in a matter of hours, and they are efficiently  compiled into the GUI of a prover. We implemented the KeY system, an interactive theorem prover for  the full JAVA CARD language based on taclets.},
  author = {Beckert, Bernhard and Giese, Martin and Habermalz, Elmar and H{\"a}hnle, Reiner and Roth, Andreas and R{\"u}mmer, Philipp and Schlager, Steffen},
  file = {files/374/Beckert et al. - Taclets A New Paradigm for Constructing Interacti.pdf;files/373/summary.html}
}

@misc{donaldopedersoncenterforelectronicsystemsdesignIntroductionFormalVerification,
  title = {Introduction to {{Formal Verification}}},
  language = {en},
  journal = {Introductino to Formal Verification},
  howpublished = {https://ptolemy.berkeley.edu/projects/embedded/research/vis/doc/VisUser/vis\_user/node4.html},
  author = {{Donald O' Pederson Center for Electronic Systems Design}},
  file = {files/376/node4.html}
}

@misc{eetimes-asiaWhatFormalVerification,
  title = {What Is Formal Verification?},
  journal = {What is formal verification?},
  howpublished = {https://archive.eetasia.com/www.eetasia.com/ART\_8800607430\_480100\_TA\_7e47bbe1.HTM},
  author = {{EE Times-Asia}},
  file = {files/378/ART_8800607430_480100_TA_7e47bbe1.html}
}

@book{DBLP:reference/dmkdh/2010,
  title = {Data {{Mining}} and {{Knowledge Discovery Handbook}}, 2nd Ed},
  isbn = {978-0-387-09822-7},
  publisher = {{Springer}},
  editor = {Maimon, Oded and Rokach, Lior},
  year = {2010},
  biburl = {https://dblp.org/rec/bib/reference/dmkdh/2010},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Denzinger99learningfrom,
  title = {Learning {{From Previous Proof Experience}}: {{A Survey}}},
  author = {Denzinger, J{\"o}rg and Fuchs, Matthias and Goller, Christoph and Schulz, Stephan},
  year = {1999}
}

@techreport{Thrun:1992:EER:865072,
  address = {{Pittsburgh, PA, USA}},
  title = {Efficient {{Exploration In Reinforcement Learning}}},
  institution = {{Carnegie Mellon University}},
  author = {Thrun, Sebastian B.},
  year = {1992},
  source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai\%3Ancstrlh\%3Acmucs\%3ACMU\%2F\%2FCS-92-102}
}

@inproceedings{Wohlin:2014:GSS:2601248.2601268,
  series = {{{EASE}} '14},
  title = {Guidelines for {{Snowballing}} in {{Systematic Literature Studies}} and a {{Replication}} in {{Software Engineering}}},
  isbn = {978-1-4503-2476-2},
  booktitle = {Proceedings of the 18th {{International Conference}} on {{Evaluation}} and {{Assessment}} in {{Software Engineering}}},
  publisher = {{ACM}},
  doi = {10.1145/2601248.2601268},
  author = {Wohlin, Claes},
  year = {2014},
  keywords = {replication,snowball search,snowballing,systematic literature review,systematic mapping studies},
  pages = {38:1-38:10},
  articleno = {38},
  numpages = {10},
  acmid = {2601268}
}

@article{DBLP:journals/corr/abs-1301-2279,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1301.2279},
  title = {A {{Bayesian Approach}} to {{Tackling Hard Computational Problems}}},
  volume = {abs/1301.2279},
  journal = {CoRR},
  author = {Horvitz, Eric and Ruan, Yongshao and Gomes, Carla P. and Kautz, Henry A. and Selman, Bart and Chickering, David Maxwell},
  year = {2013},
  biburl = {https://dblp.org/rec/bib/journals/corr/abs-1301-2279},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/mochart/AraragiC06,
  title = {Checking {{Liveness Properties}} of {{Concurrent Systems}} by {{Reinforcement Learning}}},
  booktitle = {Model {{Checking}} and {{Artificial Intelligence}}, 4th {{Workshop}}, {{MoChArt IV}}, {{Riva}} Del {{Garda}}, {{Italy}}, {{August}} 29, 2006, {{Revised Selected}} and {{Invited Papers}}},
  doi = {10.1007/978-3-540-74128-2\_6},
  author = {Araragi, Tadashi and Cho, Seung Mo},
  year = {2006},
  pages = {84-94},
  crossref = {DBLP:conf/mochart/2006},
  biburl = {https://dblp.org/rec/bib/conf/mochart/AraragiC06},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:conf/mochart/2006,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Model {{Checking}} and {{Artificial Intelligence}}, 4th {{Workshop}}, {{MoChArt IV}}, {{Riva}} Del {{Garda}}, {{Italy}}, {{August}} 29, 2006, {{Revised Selected}} and {{Invited Papers}}},
  volume = {4428},
  isbn = {978-3-540-74127-5},
  publisher = {{Springer}},
  editor = {Edelkamp, Stefan and Lomuscio, Alessio},
  year = {2007},
  doi = {10.1007/978-3-540-74128-2},
  biburl = {https://dblp.org/rec/bib/conf/mochart/2006},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:series/lncs/10001,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Deductive {{Software Verification}} - {{The KeY Book}} - {{From Theory}} to {{Practice}}},
  volume = {10001},
  isbn = {978-3-319-49811-9},
  publisher = {{Springer}},
  editor = {Ahrendt, Wolfgang and Beckert, Bernhard and Bubel, Richard and H{\"a}hnle, Reiner and Schmitt, Peter H. and Ulbrich, Mattias},
  year = {2016},
  doi = {10.1007/978-3-319-49812-6},
  biburl = {https://dblp.org/rec/bib/series/lncs/10001},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{article,
  title = {Learning {{Method Outlines}} in {{Proof Planning}}},
  author = {Jamnik, Mateja and Kerber, Manfred},
  month = feb,
  year = {1970}
}

@book{Goodfellow-et-al-2016,
  title = {Deep {{Learning}}},
  publisher = {{MIT Press}},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  note = {http://www.deeplearningbook.org}
}

@article{zheng2016feature,
  title = {Feature {{Engineering}} for {{Machine Learning Models}}: {{Principles}} and {{Techniques}} for {{Data Scientists}}},
  author = {Zheng, Alice and Casari, Amanda},
  year = {2016},
  publisher = {{New York: O'Reilly Media}}
}

@article{DBLP:journals/jmlr/GuyonE03,
  title = {An {{Introduction}} to {{Variable}} and {{Feature Selection}}},
  volume = {3},
  journal = {Journal of Machine Learning Research},
  author = {Guyon, Isabelle and Elisseeff, Andr{\'e}},
  year = {2003},
  pages = {1157-1182},
  file = {files/165/Guyon and Elisseeff - An Introduction to Variable and Feature Selection.pdf},
  biburl = {https://dblp.org/rec/bib/journals/jmlr/GuyonE03},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{guyon2008feature,
  title = {Feature Extraction: Foundations and Applications},
  volume = {207},
  publisher = {{Springer}},
  author = {Guyon, Isabelle and Gunn, Steve and Nikravesh, Masoud and Zadeh, Lofti A},
  year = {2008}
}

@inproceedings{DBLP:conf/aaai/SamulowitzM07,
  title = {Learning to {{Solve QBF}}},
  booktitle = {Proceedings of the {{Twenty}}-{{Second AAAI Conference}} on {{Artificial Intelligence}}, {{July}} 22-26, 2007, {{Vancouver}}, {{British Columbia}}, {{Canada}}},
  author = {Samulowitz, Horst and Memisevic, Roland},
  year = {2007},
  pages = {255-260},
  crossref = {DBLP:conf/aaai/2007},
  biburl = {https://dblp.org/rec/bib/conf/aaai/SamulowitzM07},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:conf/aaai/2007,
  title = {Proceedings of the {{Twenty}}-{{Second AAAI Conference}} on {{Artificial Intelligence}}, {{July}} 22-26, 2007, {{Vancouver}}, {{British Columbia}}, {{Canada}}},
  isbn = {978-1-57735-323-2},
  publisher = {{AAAI Press}},
  year = {2007},
  biburl = {https://dblp.org/rec/bib/conf/aaai/2007},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/nips/WangTWD17,
  title = {Premise {{Selection}} for {{Theorem Proving}} by {{Deep Graph Embedding}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 30: {{Annual Conference}} on {{Neural Information Processing Systems}} 2017, 4-9 {{December}} 2017, {{Long Beach}}, {{CA}}, {{USA}}},
  author = {Wang, Mingzhe and Tang, Yihe and Wang, Jian and Deng, Jia},
  year = {2017},
  pages = {2783-2793},
  file = {files/249/Wang et al. - Premise Selection for Theorem Proving by Deep Grap.pdf},
  crossref = {DBLP:conf/nips/2017},
  biburl = {https://dblp.org/rec/bib/conf/nips/WangTWD17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:conf/nips/2017,
  title = {Advances in {{Neural Information Processing Systems}} 30: {{Annual Conference}} on {{Neural Information Processing Systems}} 2017, 4-9 {{December}} 2017, {{Long Beach}}, {{CA}}, {{USA}}},
  editor = {Guyon, Isabelle and {von Luxburg}, Ulrike and Bengio, Samy and Wallach, Hanna M. and Fergus, Rob and Vishwanathan, S. V. N. and Garnett, Roman},
  year = {2017},
  biburl = {https://dblp.org/rec/bib/conf/nips/2017},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/nips/KaliszykUMO18,
  title = {Reinforcement {{Learning}} of {{Theorem Proving}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 31: {{Annual Conference}} on {{Neural Information Processing Systems}} 2018, {{NeurIPS}} 2018, 3-8 {{December}} 2018, {{Montr{\'e}al}}, {{Canada}}.},
  author = {Kaliszyk, Cezary and Urban, Josef and Michalewski, Henryk and Ols{\'a}k, Miroslav},
  year = {2018},
  pages = {8836-8847},
  file = {files/233/Kaliszyk et al. - Reinforcement Learning of Theorem Proving.pdf},
  crossref = {DBLP:conf/nips/2018},
  biburl = {https://dblp.org/rec/bib/conf/nips/KaliszykUMO18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:conf/nips/2018,
  title = {Advances in {{Neural Information Processing Systems}} 31: {{Annual Conference}} on {{Neural Information Processing Systems}} 2018, {{NeurIPS}} 2018, 3-8 {{December}} 2018, {{Montr{\'e}al}}, {{Canada}}},
  editor = {Bengio, Samy and Wallach, Hanna M. and Larochelle, Hugo and Grauman, Kristen and {Cesa-Bianchi}, Nicol{\`o} and Garnett, Roman},
  year = {2018},
  biburl = {https://dblp.org/rec/bib/conf/nips/2018},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:books/lib/SuttonB98,
  series = {Adaptive Computation and Machine Learning},
  title = {Reinforcement Learning - an Introduction},
  isbn = {0-262-19398-1},
  publisher = {{MIT Press}},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {1998},
  biburl = {https://dblp.org/rec/bib/books/lib/SuttonB98},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:books/hal/Fontaine18,
  title = {Satisfiability {{Modulo Theories}}: State-of-the-Art, Contributions, Project. ({{Satisfaisabilit{\'e} Modulo Th{\'e}ories}}: {\'E}tat de l'art, Contributions, Projet)},
  author = {Fontaine, Pascal},
  year = {2018},
  biburl = {https://dblp.org/rec/bib/books/hal/Fontaine18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:books/sp/BultanYAA17,
  title = {String {{Analysis}} for {{Software Verification}} and {{Security}}},
  isbn = {978-3-319-68668-4},
  publisher = {{Springer}},
  author = {Bultan, Tevfik and Yu, Fang and Alkhalaf, Muath and Aydin, Abdulbaki},
  year = {2017},
  doi = {10.1007/978-3-319-68670-7},
  biburl = {https://dblp.org/rec/bib/books/sp/BultanYAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/japll/AnsoteguiBGL17,
  title = {Structure Features for {{SAT}} Instances Classification},
  volume = {23},
  journal = {J. Applied Logic},
  doi = {10.1016/j.jal.2016.11.004},
  author = {Ans{\'o}tegui, Carlos and Bonet, Maria Luisa and {Gir{\'a}ldez-Cru}, Jes{\'u}s and Levy, Jordi},
  year = {2017},
  pages = {27-39},
  biburl = {https://dblp.org/rec/bib/journals/japll/AnsoteguiBGL17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@phdthesis{DBLP:phd/ethos/Duncan07,
  title = {The Use of Data-Mining for the Automatic Formation of Tactics},
  school = {University of Edinburgh, UK},
  author = {Duncan, Hazel},
  year = {2007},
  file = {files/108/Duncan et al. - The Use of Data-Mining for the Automatic Formation.pdf},
  biburl = {https://dblp.org/rec/bib/phd/ethos/Duncan07},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/cade/Paulson10,
  title = {Three {{Years}} of {{Experience}} with {{Sledgehammer}}, a {{Practical Link}} between {{Automatic}} and {{Interactive Theorem Provers}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Practical Aspects}} of {{Automated Reasoning}}, {{PAAR}}-2010, {{Edinburgh}}, {{Scotland}}, {{UK}}, {{July}} 14, 2010},
  author = {Paulson, Lawrence C.},
  year = {2010},
  pages = {1-10},
  crossref = {DBLP:conf/cade/2010paar},
  biburl = {https://dblp.org/rec/bib/conf/cade/Paulson10},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:conf/cade/2010paar,
  series = {{{EPiC Series}} in {{Computing}}},
  title = {Proceedings of the 2nd {{Workshop}} on {{Practical Aspects}} of {{Automated Reasoning}}, {{PAAR}}-2010, {{Edinburgh}}, {{Scotland}}, {{UK}}, {{July}} 14, 2010},
  volume = {9},
  publisher = {{EasyChair}},
  editor = {Schmidt, Renate A. and Schulz, Stephan and Konev, Boris},
  year = {2012},
  biburl = {https://dblp.org/rec/bib/conf/cade/2010paar},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:conf/sat/2016,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Theory and {{Applications}} of {{Satisfiability Testing}} - {{SAT}} 2016 - 19th {{International Conference}}, {{Bordeaux}}, {{France}}, {{July}} 5-8, 2016, {{Proceedings}}},
  volume = {9710},
  isbn = {978-3-319-40969-6},
  publisher = {{Springer}},
  editor = {Creignou, Nadia and Berre, Daniel Le},
  year = {2016},
  doi = {10.1007/978-3-319-40970-2},
  biburl = {https://dblp.org/rec/bib/conf/sat/2016},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lagoudakisReinforcementLearningClassification,
  title = {Reinforcement {{Learning}} as {{Classification}}: {{Leveraging Modern Classifiers}}},
  abstract = {The basic tools of machine learning appear in the inner loop of most reinforcement learning algorithms, typically in the form of Monte Carlo methods or function approximation techniques. To a large extent, however, current reinforcement learning algorithms draw upon machine learning techniques that are at least ten years old and, with a few exceptions, very little has been done to exploit recent advances in classification learning for the purposes of reinforcement learning. We use a variant of approximate policy iteration based on rollouts that allows us to use a pure classification learner, such as a support vector machine (SVM), in the inner loop of the algorithm. We argue that the use of SVMs, particularly in combination with the kernel trick, can make it easier to apply reinforcement learning as an ``outof-the-box'' technique, without extensive feature engineering. Our approach opens the door to modern classification methods, but does not preclude the use of classical methods. We present experimental results in the pendulum balancing and bicycle riding domains using both SVMs and neural networks for classifiers.},
  language = {en},
  author = {Lagoudakis, Michail and Parr, Ronald},
  pages = {8},
  file = {files/420/Lagoudakis and Parr - Reinforcement Learning as Classification Leveragi.pdf}
}

@article{baconOptionCriticArchitecture2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1609.05140},
  primaryClass = {cs},
  title = {The {{Option}}-{{Critic Architecture}}},
  abstract = {Temporal abstraction is key to scaling up learning and planning in reinforcement learning. While planning with temporally extended actions is well understood, creating such abstractions autonomously from data has remained challenging. We tackle this problem in the framework of options [Sutton, Precup \& Singh, 1999; Precup, 2000]. We derive policy gradient theorems for options and propose a new option-critic architecture capable of learning both the internal policies and the termination conditions of options, in tandem with the policy over options, and without the need to provide any additional rewards or subgoals. Experimental results in both discrete and continuous environments showcase the flexibility and efficiency of the framework.},
  language = {en},
  journal = {arXiv:1609.05140 [cs]},
  author = {Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  month = sep,
  year = {2016},
  keywords = {Computer Science - Artificial Intelligence},
  file = {files/423/Bacon et al. - 2016 - The Option-Critic Architecture.pdf}
}

@article{dietterichHierarchicalReinforcementLearning1999,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {cs/9905014},
  title = {Hierarchical {{Reinforcement Learning}} with the {{MAXQ Value Function Decomposition}}},
  abstract = {This paper presents a new approach to hierarchical reinforcement learning based on decomposing the target Markov decision process (MDP) into a hierarchy of smaller MDPs and decomposing the value function of the target MDP into an additive combination of the value functions of the smaller MDPs. The decomposition, known as the MAXQ decomposition, has both a procedural semantics\textemdash{}as a subroutine hierarchy\textemdash{}and a declarative semantics\textemdash{}as a representation of the value function of a hierarchical policy. MAXQ unifies and extends previous work on hierarchical reinforcement learning by Singh, Kaelbling, and Dayan and Hinton. It is based on the assumption that the programmer can identify useful subgoals and define subtasks that achieve these subgoals. By defining such subgoals, the programmer constrains the set of policies that need to be considered during reinforcement learning. The MAXQ value function decomposition can represent the value function of any policy that is consistent with the given hierarchy. The decomposition also creates opportunities to exploit state abstractions, so that individual MDPs within the hierarchy can ignore large parts of the state space. This is important for the practical application of the method. This paper defines the MAXQ hierarchy, proves formal results on its representational power, and establishes five conditions for the safe use of state abstractions. The paper presents an online model-free learning algorithm, MAXQ-Q, and proves that it converges wih probability 1 to a kind of locally-optimal policy known as a recursively optimal policy, even in the presence of the five kinds of state abstraction. The paper evaluates the MAXQ representation and MAXQ-Q through a series of experiments in three domains and shows experimentally that MAXQ-Q (with state abstractions) converges to a recursively optimal policy much faster than flat Q learning. The fact that MAXQ learns a representation of the value function has an important benefit: it makes it possible to compute and execute an improved, non-hierarchical policy via a procedure similar to the policy improvement step of policy iteration. The paper demonstrates the effectiveness of this non-hierarchical execution experimentally. Finally, the paper concludes with a comparison to related work and a discussion of the design tradeoffs in hierarchical reinforcement learning.},
  language = {en},
  journal = {arXiv:cs/9905014},
  author = {Dietterich, Thomas G.},
  month = may,
  year = {1999},
  keywords = {Computer Science - Machine Learning,I.2.6},
  file = {files/426/Dietterich - 1999 - Hierarchical Reinforcement Learning with the MAXQ .pdf}
}

@misc{PromiseHierarchicalReinforcement2019,
  title = {The {{Promise}} of {{Hierarchical Reinforcement Learning}}},
  abstract = {This idea of temporal abstraction, once incorporated into reinforcement learning (RL), converts it into *hierarchical* reinforcement learning (HRL).},
  language = {en},
  journal = {The Gradient},
  howpublished = {https://thegradient.pub/the-promise-of-hierarchical-reinforcement-learning/},
  month = mar,
  year = {2019},
  file = {files/430/the-promise-of-hierarchical-reinforcement-learning.html}
}

@article{botvinickHierarchicallyOrganizedBehavior2009,
  series = {Reinforcement Learning and Higher Cognition},
  title = {Hierarchically Organized Behavior and Its Neural Foundations: {{A}} Reinforcement Learning Perspective},
  volume = {113},
  issn = {0010-0277},
  shorttitle = {Hierarchically Organized Behavior and Its Neural Foundations},
  abstract = {Research on human and animal behavior has long emphasized its hierarchical structure\textemdash{}the divisibility of ongoing behavior into discrete tasks, which are comprised of subtask sequences, which in turn are built of simple actions. The hierarchical structure of behavior has also been of enduring interest within neuroscience, where it has been widely considered to reflect prefrontal cortical functions. In this paper, we reexamine behavioral hierarchy and its neural substrates from the point of view of recent developments in computational reinforcement learning. Specifically, we consider a set of approaches known collectively as hierarchical reinforcement learning, which extend the reinforcement learning paradigm by allowing the learning agent to aggregate actions into reusable subroutines or skills. A close look at the components of hierarchical reinforcement learning suggests how they might map onto neural structures, in particular regions within the dorsolateral and orbital prefrontal cortex. It also suggests specific ways in which hierarchical reinforcement learning might provide a complement to existing psychological models of hierarchically structured behavior. A particularly important question that hierarchical reinforcement learning brings to the fore is that of how learning identifies new action routines that are likely to provide useful building blocks in solving a wide range of future problems. Here and at many other points, hierarchical reinforcement learning offers an appealing framework for investigating the computational and neural underpinnings of hierarchically structured behavior.},
  number = {3},
  journal = {Cognition},
  doi = {10.1016/j.cognition.2008.08.011},
  author = {Botvinick, Matthew M. and Niv, Yael and Barto, Andrew C.},
  month = dec,
  year = {2009},
  keywords = {Prefrontal cortex,Reinforcement learning},
  pages = {262-280},
  file = {files/433/Botvinick et al. - 2009 - Hierarchically organized behavior and its neural f.pdf;files/432/S0010027708002059.html}
}

@inproceedings{weiSupervisedDeepFeatures2017,
  address = {{Melbourne, Australia}},
  title = {Supervised {{Deep Features}} for {{Software Functional Clone Detection}} by {{Exploiting Lexical}} and {{Syntactical Information}} in {{Source Code}}},
  isbn = {978-0-9992411-0-3},
  abstract = {Software clone detection, aiming at identifying out code fragments with similar functionalities, has played an important role in software maintenance and evolution. Many clone detection approaches have been proposed. However, most of them represent source codes with hand-crafted features using lexical or syntactical information, or unsupervised deep features, which makes it difficult to detect the functional clone pairs, i.e., pieces of codes with similar functionality but differing in both syntactical and lexical level. In this paper, we address the software functional clone detection problem by learning supervised deep features. We formulate the clone detection as a supervised learning to hash problem and propose an end-to-end deep feature learning framework called CDLH for functional clone detection. Such framework learns hash codes by exploiting the lexical and syntactical information for fast computation of functional similarity between code fragments. Experiments on software clone detection benchmarks indicate that the CDLH approach is effective and outperforms the state-of-the-art approaches in software functional clone detection.},
  language = {en},
  booktitle = {Proceedings of the {{Twenty}}-{{Sixth International Joint Conference}} on {{Artificial Intelligence}}},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  doi = {10.24963/ijcai.2017/423},
  author = {Wei, Huihui and Li, Ming},
  month = aug,
  year = {2017},
  pages = {3034-3040},
  file = {files/453/Wei and Li - 2017 - Supervised Deep Features for Software Functional C.pdf}
}

@book{margariaLeveragingApplicationsFormal2018,
  address = {{Cham}},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Leveraging {{Applications}} of {{Formal Methods}}, {{Verification}} and {{Validation}}. {{Verification}}: 8th {{International Symposium}}, {{ISoLA}} 2018, {{Limassol}}, {{Cyprus}}, {{November}} 5-9, 2018, {{Proceedings}}, {{Part II}}},
  volume = {11245},
  isbn = {978-3-030-03420-7 978-3-030-03421-4},
  shorttitle = {Leveraging {{Applications}} of {{Formal Methods}}, {{Verification}} and {{Validation}}. {{Verification}}},
  language = {en},
  publisher = {{Springer International Publishing}},
  editor = {Margaria, Tiziana and Steffen, Bernhard},
  year = {2018},
  doi = {10.1007/978-3-030-03421-4}
}

@article{gabmeyerFeaturebasedClassificationFormal2019,
  title = {A Feature-Based Classification of Formal Verification Techniques for Software Models},
  volume = {18},
  issn = {1619-1366, 1619-1374},
  abstract = {Software models are the core development artifact in model-based engineering (MBE). The MBE paradigm promotes the use of software models to describe structure and behavior of the system under development and proposes the automatic generation of executable code from the models. Thus, defects in the models most likely propagate to executable code. To detect defects already at the modeling level, many approaches propose to use formal verification techniques to ensure the correctness of these models. These approaches are the subject of this survey. We review the state of the art of formal verification techniques for software models and provide a feature-based classification that allows us to categorize and compare the different approaches.},
  language = {en},
  number = {1},
  journal = {Softw Syst Model},
  doi = {10.1007/s10270-017-0591-z},
  author = {Gabmeyer, Sebastian and Kaufmann, Petra and Seidl, Martina and Gogolla, Martin and Kappel, Gerti},
  month = feb,
  year = {2019},
  pages = {473-498},
  file = {files/457/Gabmeyer et al. - 2019 - A feature-based classification of formal verificat.pdf}
}

@article{shippeyAutomaticallyIdentifyingCode2019,
  title = {Automatically Identifying Code Features for Software Defect Prediction: {{Using AST N}}-Grams},
  volume = {106},
  issn = {09505849},
  shorttitle = {Automatically Identifying Code Features for Software Defect Prediction},
  language = {en},
  journal = {Information and Software Technology},
  doi = {10.1016/j.infsof.2018.10.001},
  author = {Shippey, Thomas and Bowes, David and Hall, Tracy},
  month = feb,
  year = {2019},
  pages = {142-160}
}

@inproceedings{harrisRecognizersExtractingArchitectural1995,
  title = {Recognizers for Extracting Architectural Features from Source Code},
  abstract = {Architectural representation can play a pivotal role throughout the life cycle of any software program. In particular, we are interested in the role it plays in the maintenance/evolution of legacy programs. During these phases, analysts often describe programs using architectural terminology (e.g., "interfaces", "interprocess communication", "layers", "objects"). Our research and development goals center on supporting such activities through architectural recovery tools that are based on reverse engineering technology. These tools start with existing source code and extract architecture-level descriptions. We have implemented a framework for architectural recovery and our experience leads us to several observations about the representational needs of a library that is populated with families of architecture recognition rules. This paper characterizes the kinds of recognizers we have developed and describes an approach for rule parameterization and retrieval.},
  booktitle = {Proceedings of 2nd {{Working Conference}} on {{Reverse Engineering}}},
  doi = {10.1109/WCRE.1995.514713},
  author = {Harris, D. R. and Reubenstein, H. B. and Yeh, A. S.},
  month = jul,
  year = {1995},
  keywords = {feature extraction,Feature extraction,software maintenance,Software maintenance,architectural recovery tools,architectural representation,architecture recognition rules,architecture-level descriptions,Character recognition,Computer architecture,Indexing,legacy program evolution,library,Maintenance engineering,Research and development,reverse engineering,Reverse engineering,rule parameterization,rule retrieval,software libraries,Software libraries,software life cycle,software tools,source code,source code architectural feature extraction,Terminology},
  pages = {252-261},
  file = {files/460/Harris et al. - 1995 - Recognizers for extracting architectural features .pdf;files/462/514713.html}
}

@article{panSurveyTransferLearning2010,
  title = {A {{Survey}} on {{Transfer Learning}}},
  volume = {22},
  issn = {1041-4347},
  abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
  number = {10},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  doi = {10.1109/TKDE.2009.191},
  author = {Pan, S. J. and Yang, Q.},
  month = oct,
  year = {2010},
  keywords = {Machine learning,machine learning,survey,data mining,Data mining,Training data,data mining.,inductive transfer learning,knowledge engineering,Knowledge engineering,knowledge transfer,Knowledge transfer,Labeling,learning by example,Learning systems,Machine learning algorithms,optimisation,Space technology,Testing,transductive transfer learning,Transfer learning,unsupervised learning,unsupervised transfer learning},
  pages = {1345-1359},
  file = {files/466/Pan and Yang - 2010 - A Survey on Transfer Learning.pdf;files/465/5288526.html}
}

@article{lawsonWhatRoleInduction2005,
  title = {What Is the Role of Induction and Deduction in Reasoning and Scientific Inquiry?},
  volume = {42},
  issn = {1098-2736},
  abstract = {A long-standing and continuing controversy exists regarding the role of induction and deduction in reasoning and in scientific inquiry. Given the inherent difficulty in reconstructing reasoning patterns based on personal and historical accounts, evidence about the nature of human reasoning in scientific inquiry has been sought from a controlled experiment designed to identify the role played by enumerative induction and deduction in cognition as well as from the relatively new field of neural modeling. Both experimental results and the neurological models imply that induction across a limited set of observations plays no role in task performance and in reasoning. Therefore, support has been obtained for Popper's hypothesis that enumerative induction does not exist as a psychological process. Instead, people appear to process information in terms of increasingly abstract cycles of hypothetico-deductive reasoning. Consequently, science instruction should provide students with opportunities to generate and test increasingly complex and abstract hypotheses and theories in a hypothetico-deductive manner. In this way students can be expected to become increasingly conscious of their underlying hypothetico-deductive thought processes, increasingly skilled in their application, and hence increasingly scientifically literate. \textcopyright{} 2005 Wiley Periodicals, Inc. J Res Sci Teach},
  language = {en},
  number = {6},
  journal = {Journal of Research in Science Teaching},
  doi = {10.1002/tea.20067},
  author = {Lawson, Anton E.},
  year = {2005},
  pages = {716-740},
  file = {files/470/Lawson - 2005 - What is the role of induction and deduction in rea.pdf;files/469/tea.html}
}

@article{azizMachineLearningTechnique,
  title = {A {{Machine Learning Technique}} for {{Hardness Estimation}} of {{QFBV SMT Problems}} ({{Work}} in Progress)},
  abstract = {In this paper, we present a new approach for measuring the expected runtimes (hardness) of SMT problems. The required features, the statistical hardness model used and the machine learning technique which we used are presented. The method is applied to estimate the hardness of problems in the Quanti er Free Bit Vector (QFBV) theory and we used four of the contesting solvers in SMTCOMP2011 to demonstrate the technique. We have qualitatively expanded some propositional SAT features existing in the literature to directly work on general SMT problem instances without preprocessing. Experimental results with the standard set of benchmarks are promising and our implementation proves the concept.},
  language = {en},
  author = {Aziz, Mohammad Abdul and Wassal, Amr and Darwish, Nevine},
  pages = {10},
  file = {files/472/Aziz et al. - A Machine Learning Technique for Hardness Estimati.pdf}
}

@inproceedings{kaliszykStrongerAutomationFlyspeck,
  title = {Stronger {{Automation}} for {{Flyspeck}} by {{Feature Weighting}} and {{Strategy Evolution}}},
  abstract = {Two complementary AI methods are used to improve the strength of the AI/ATP service for proving conjectures over the HOL Light and Flyspeck corpora. First, several schemes for frequency-based feature weighting are explored in combination with distanceweighted k-nearest-neighbor classifier. This results in 16\% improvement (39.0\% to 45.5\% Flyspeck problems solved) of the overall strength of the service when using 14 CPUs and 30 seconds. The best premise-selection/ATP combination is improved from 24.2\% to 31.4\%, i.e. by 30\%. A smaller improvement is obtained by evolving targetted E prover strategies on two particular premise selections, using the Blind Strategymaker (BliStr) system. This raises the performance of the best AI/ATP method from 31.4\% to 34.9\%, i.e. by 11\%, and raises the current 14-CPU power of the service to 46.9\%.},
  language = {en},
  booktitle = {{{PxTP}} 2013. {{Third International Workshop}} on {{Proof Exchange}} for {{Theorem Proving}}},
  doi = {10.29007/5gzr},
  author = {Kaliszyk, Cezary and Urban, Josef},
  pages = {87-77},
  file = {files/475/Kaliszyk and Urban - Stronger Automation for Flyspeck by Feature Weight.pdf}
}

@article{kimMindGapGenerative,
  title = {Mind the {{Gap}}: {{A Generative Approach}} to {{Interpretable Feature Selection}} and {{Extraction}}},
  abstract = {We present the Mind the Gap Model (MGM), an approach for interpretable feature extraction and selection. By placing interpretability criteria directly into the model, we allow for the model to both optimize parameters related to interpretability and to directly report a global set of distinguishable dimensions to assist with further data exploration and hypothesis generation. MGM extracts distinguishing features on real-world datasets of animal features, recipes ingredients, and disease co-occurrence. It also maintains or improves performance when compared to related approaches. We perform a user study with domain experts to show the MGM's ability to help with dataset exploration.},
  language = {en},
  author = {Kim, Been and Shah, Julie A and {Doshi-Velez}, Finale},
  pages = {9},
  file = {files/478/Kim et al. - Mind the Gap A Generative Approach to Interpretab.pdf}
}

@article{balunovicLearningSolveSMT,
  title = {Learning to {{Solve SMT Formulas}}},
  abstract = {We present a new approach for learning to solve SMT formulas. We phrase the challenge of solving SMT formulas as a tree search problem where at each step a transformation is applied to the input formula until the formula is solved. Our approach works in two phases: first, given a dataset of unsolved formulas we learn a policy that for each formula selects a suitable transformation to apply at each step in order to solve the formula, and second, we synthesize a strategy in the form of a loop-free program with branches. This strategy is an interpretable representation of the policy decisions and is used to guide the SMT solver to decide formulas more efficiently, without requiring any modification to the solver itself and without needing to evaluate the learned policy at inference time. We show that our approach is effective in practice \textendash{} it solves 17\% more formulas over a range of benchmarks and achieves up to 100\texttimes{} runtime improvement over a state-of-the-art SMT solver.},
  language = {en},
  author = {Balunovic, Mislav and Bielik, Pavol and Vechev, Martin},
  pages = {12},
  file = {files/481/Balunovic et al. - Learning to Solve SMT Formulas.pdf}
}

@article{kaliszykEfficientSemanticFeaturesa,
  title = {Efficient {{Semantic Features}} for {{Automated Reasoning}} over {{Large Theories}}},
  abstract = {Large formal mathematical knowledge bases encode considerable parts of advanced mathematics and exact science, allowing deep semantic computer assistance and verification of complicated theories down to the atomic logical rules. An essential part of automated reasoning over such large theories are methods learning selection of relevant knowledge from the thousands of proofs in the corpora. Such methods in turn rely on efficiently computable features characterizing the highly structured and inter-related mathematical statements.},
  language = {en},
  author = {Kaliszyk, Cezary and Urban, Josef and Vyskocil, Jiri},
  pages = {7},
  file = {files/484/Kaliszyk et al. - Efficient Semantic Features for Automated Reasonin.pdf}
}

@article{hevnerDesignScienceInformation,
  title = {Design {{Science}} in {{Information Systems Research}}},
  language = {en},
  author = {Hevner, Alan R and March, Salvatore T and Park, Jinsoo and Ram, Sudha},
  pages = {32},
  file = {files/498/Hevner et al. - Design Science in Information Systems Research.pdf}
}

@article{zhuReinforcementLearningTrees2015,
  title = {Reinforcement {{Learning Trees}}},
  volume = {110},
  issn = {0162-1459, 1537-274X},
  language = {en},
  number = {512},
  journal = {Journal of the American Statistical Association},
  doi = {10.1080/01621459.2015.1036994},
  author = {Zhu, Ruoqing and Zeng, Donglin and Kosorok, Michael R.},
  month = oct,
  year = {2015},
  pages = {1770-1784},
  file = {files/531/Zhu et al. - 2015 - Reinforcement Learning Trees.pdf}
}

@misc{yauIntroductionReinforcementLearning2018,
  title = {An {{Introduction}} to {{Reinforcement Learning Q}}-{{Learning}} with {{Decision Trees}}},
  abstract = {Reinforcement learning (RL) is a paradigm in machine learning where computer learns to perform tasks such as driving a vehicle, playing\ldots{}},
  language = {en},
  journal = {Medium},
  howpublished = {https://towardsdatascience.com/reinforcement-learning-q-learning-with-decision-trees-ecb1215d9131},
  author = {Yau, Chakrit},
  month = nov,
  year = {2018},
  file = {files/535/reinforcement-learning-q-learning-with-decision-trees-ecb1215d9131.html}
}

@misc{DeepReinforcementLearninga,
  title = {Deep {{Reinforcement Learning Doesn}}'t {{Work Yet}}},
  abstract = {June 24, 2018 note: If you want to cite an example from the post, please
cite the paper which that example came from. If you want to cite the
post as a whole, you can use the following BibTeX:},
  howpublished = {http://www.alexirpan.com/2018/02/14/rl-hard.html},
  file = {files/537/rl-hard.html}
}

@article{taiTreetoTreeCorrectionProblem,
  title = {The {{Tree}}-to-{{Tree Correction Problem}}},
  language = {en},
  journal = {The Tree},
  author = {Tai, Kuo-Chung},
  pages = {12},
  file = {files/544/Tai - The Tree-to-Tree Correction Problem.pdf}
}

@article{zhangSimpleFastAlgorithms1989,
  title = {Simple {{Fast Algorithms}} for the {{Editing Distance}} between {{Trees}} and {{Related Problems}}},
  volume = {18},
  issn = {0097-5397, 1095-7111},
  abstract = {Ordered labeled trees are trees in which the left-to-right order among siblings is. significant. The distance between two ordered trees is considered to be the weighted number of edit operations (insert, delete, and modify) to transform one tree to another. The problem of approximate tree matching is also considered. Specifically, algorithms are designed to answer the following kinds of questions: 1. What is the distance between two trees? 2. What is the minimum distance between T and T when zero or more subtrees can be removed from T2 3. Let the pruning of a tree at node n mean removing all the descendants of node n. The analogous question for prunings as for subtrees is answered. A dynamic programming algorithm is presented to solve the three questions in sequential time O(I Tll x IT2lxmin (depth( Tt), leaves( T)) x min (depth(T2), leaves(T2))) and space O(Ir, x lT21) compared with o(I T,I IT=I x(depth(T)): x (depth(T2))) for the best previous published algorithm due to Tai [J. Assoc. Comput. Mach., 26 (1979), pp. 422-433]. Further, the algorithm presented here can be parallelized to give time O(1 T[ /1 T=I).},
  language = {en},
  number = {6},
  journal = {SIAM J. Comput.},
  doi = {10.1137/0218082},
  author = {Zhang, Kaizhong and Shasha, Dennis},
  month = dec,
  year = {1989},
  pages = {1245-1262},
  file = {files/546/Zhang and Shasha - 1989 - Simple Fast Algorithms for the Editing Distance be.pdf}
}


@article{zhangSimpleFastAlgorithms1989,
	title = {Simple {Fast} {Algorithms} for the {Editing} {Distance} between {Trees} and {Related} {Problems}},
	volume = {18},
	issn = {0097-5397, 1095-7111},
	url = {http://epubs.siam.org/doi/10.1137/0218082},
	doi = {10.1137/0218082},
	abstract = {Ordered labeled trees are trees in which the left-to-right order among siblings is. significant. The distance between two ordered trees is considered to be the weighted number of edit operations (insert, delete, and modify) to transform one tree to another. The problem of approximate tree matching is also considered. Specifically, algorithms are designed to answer the following kinds of questions: 1. What is the distance between two trees? 2. What is the minimum distance between T and T when zero or more subtrees can be removed from T2 3. Let the pruning of a tree at node n mean removing all the descendants of node n. The analogous question for prunings as for subtrees is answered. A dynamic programming algorithm is presented to solve the three questions in sequential time O(I Tll x IT2lxmin (depth( Tt), leaves( T)) x min (depth(T2), leaves(T2))) and space O(Ir, x lT21) compared with o(I T,I IT=I x(depth(T)): x (depth(T2))) for the best previous published algorithm due to Tai [J. Assoc. Comput. Mach., 26 (1979), pp. 422-433]. Further, the algorithm presented here can be parallelized to give time O(1 T[ /1 T=I).},
	language = {en},
	number = {6},
	urldate = {2019-09-27},
	journal = {SIAM J. Comput.},
	author = {Zhang, Kaizhong and Shasha, Dennis},
	month = dec,
	year = {1989},
	pages = {1245--1262},
	file = {Zhang and Shasha - 1989 - Simple Fast Algorithms for the Editing Distance be.pdf:/home/andy/Zotero/storage/Y9GUJB7B/Zhang and Shasha - 1989 - Simple Fast Algorithms for the Editing Distance be.pdf:application/pdf}
}

@article{taiTreetoTreeCorrectionProblem,
	title = {The {Tree}-to-{Tree} {Correction} {Problem}},
	language = {en},
	journal = {The Tree},
	author = {Tai, Kuo-Chung},
	pages = {12},
	file = {Tai - The Tree-to-Tree Correction Problem.pdf:/home/andy/Zotero/storage/KVXEUYI2/Tai - The Tree-to-Tree Correction Problem.pdf:application/pdf}
}

@misc{dulov2016bwcloud,
  title={bwCloud: cross-site server virtualization},
  author={Dulov, OV},
  year={2016}
}

@misc{DeepReinforcementLearning,
	title = {Deep {Reinforcement} {Learning} {Doesn}'t {Work} {Yet}},
	url = {http://www.alexirpan.com/2018/02/14/rl-hard.html},
	abstract = {June 24, 2018 note: If you want to cite an example from the post, please
cite the paper which that example came from. If you want to cite the
post as a whole, you can use the following BibTeX:},
	urldate = {2019-09-15},
	file = {Snapshot:/home/andy/Zotero/storage/KMUJUU8X/rl-hard.html:text/html}
}

@misc{yauIntroductionReinforcementLearning2018,
	title = {An {Introduction} to {Reinforcement} {Learning} {Q}-{Learning} with {Decision} {Trees}},
	url = {https://towardsdatascience.com/reinforcement-learning-q-learning-with-decision-trees-ecb1215d9131},
	abstract = {Reinforcement learning (RL) is a paradigm in machine learning where computer learns to perform tasks such as driving a vehicle, playing…},
	language = {en},
	urldate = {2019-09-15},
	journal = {Medium},
	author = {Yau, Chakrit},
	month = nov,
	year = {2018},
	file = {Snapshot:/home/andy/Zotero/storage/7J64Y2Z9/reinforcement-learning-q-learning-with-decision-trees-ecb1215d9131.html:text/html}
}

@article{zhuReinforcementLearningTrees2015,
	title = {Reinforcement {Learning} {Trees}},
	volume = {110},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2015.1036994},
	doi = {10.1080/01621459.2015.1036994},
	language = {en},
	number = {512},
	urldate = {2019-09-15},
	journal = {Journal of the American Statistical Association},
	author = {Zhu, Ruoqing and Zeng, Donglin and Kosorok, Michael R.},
	month = oct,
	year = {2015},
	pages = {1770--1784},
	annote = {use RL to create Decision trees with maximum overall benefit on each split instead of just splitting according to where the immediate benefit is maximized.},
	file = {Zhu et al. - 2015 - Reinforcement Learning Trees.pdf:/home/andy/Zotero/storage/B428PKUA/Zhu et al. - 2015 - Reinforcement Learning Trees.pdf:application/pdf}
}

@article{nagashimaPaMpeRProofMethod2018,
	title = {{PaMpeR}: {Proof} {Method} {Recommendation} {System} for {Isabelle}/{HOL}},
	shorttitle = {{PaMpeR}},
	url = {http://arxiv.org/abs/1806.07239},
	abstract = {Deciding which sub-tool to use for a given proof state requires expertise speciﬁc to each ITP. To mitigate this problem, we present PaMpeR, a proof method recommendation system for Isabelle/HOL. Given a proof state, PaMpeR recommends proof methods to discharge the proof goal and provides qualitative explanations as to why it suggests these methods. PaMpeR generates these recommendations based on existing hand-written proof corpora, thus transferring experienced users’ expertise to new users. Our evaluation shows that PaMpeR correctly predicts experienced users’ proof methods invocation especially when it comes to special purpose proof methods.},
	language = {en},
	urldate = {2019-09-09},
	journal = {arXiv:1806.07239 [cs]},
	author = {Nagashima, Yutaka and He, Yilun},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.07239},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science},
	file = {Nagashima and He - 2018 - PaMpeR Proof Method Recommendation System for Isa.pdf:/home/andy/Zotero/storage/HYIYW923/Nagashima and He - 2018 - PaMpeR Proof Method Recommendation System for Isa.pdf:application/pdf}
}

@misc{CS188Spring2013,
	title = {{CS188Spring2013}},
	url = {https://www.youtube.com/channel/UCTmAYxRV7H9NTdgC9bNixvw},
	language = {en-US},
	urldate = {2019-09-09},
	journal = {YouTube},
	file = {Snapshot:/home/andy/Zotero/storage/K4R4CJTA/UCTmAYxRV7H9NTdgC9bNixvw.html:text/html}
}

@article{piotrowskiGuidingTheoremProving2019,
	title = {Guiding {Theorem} {Proving} by {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1905.07961},
	abstract = {We describe two theorem proving tasks – premise selection and internal guidance – for which machine learning has been recently used with some success. We argue that the existing methods however do not correspond to the way how humans approach these tasks. In particular, the existing methods so far lack the notion of a state that is updated each time a choice in the reasoning process is made. To address that, we propose an analogy with tasks such as machine translation, where stateful architectures such as recurrent neural networks have been recently very successful. Then we develop and publish a series of sequence-tosequence datasets that correspond to the theorem proving tasks using several encodings, and provide the ﬁrst experimental evaluation of the performance of recurrent neural networks on such tasks.},
	language = {en},
	urldate = {2019-09-09},
	journal = {arXiv:1905.07961 [cs, stat]},
	author = {Piotrowski, Bartosz and Urban, Josef},
	month = may,
	year = {2019},
	note = {arXiv: 1905.07961},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Logic in Computer Science, Statistics - Machine Learning},
	file = {Piotrowski and Urban - 2019 - Guiding Theorem Proving by Recurrent Neural Networ.pdf:/home/andy/Zotero/storage/Z46LU5Y2/Piotrowski and Urban - 2019 - Guiding Theorem Proving by Recurrent Neural Networ.pdf:application/pdf}
}

@inproceedings{nagashimaEvolutionaryTheoremProving2019,
	address = {Prague, Czech Republic},
	title = {Towards evolutionary theorem proving for isabelle/{HOL}},
	isbn = {978-1-4503-6748-6},
	url = {http://dl.acm.org/citation.cfm?doid=3319619.3321921},
	doi = {10.1145/3319619.3321921},
	abstract = {Mechanized theorem proving is becoming the basis of reliable systems programming and rigorous mathematics. Despite decades of progress in proof automation, writing mechanized proofs still requires engineers’ expertise and remains labor intensive. Recently, researchers have extracted heuristics of interactive proof development from existing large proof corpora using supervised learning. However, such existing proof corpora present only one way of proving conjectures, while there are often multiple equivalently effective ways to prove one conjecture. In this abstract, we identify challenges in discovering heuristics for automatic proof search and propose our novel approach to improve heuristics of automatic proof search in Isabelle/HOL using evolutionary computation.},
	language = {en},
	urldate = {2019-09-09},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference} {Companion} on   - {GECCO} '19},
	publisher = {ACM Press},
	author = {Nagashima, Yutaka},
	year = {2019},
	pages = {419--420},
	file = {Nagashima - 2019 - Towards evolutionary theorem proving for isabelle.pdf:/home/andy/Zotero/storage/67GGNU8Q/Nagashima - 2019 - Towards evolutionary theorem proving for isabelle.pdf:application/pdf}
}

@article{hevnerDesignScienceInformation,
	title = {Design {Science} in {Information} {Systems} {Research}},
	language = {en},
	author = {Hevner, Alan R and March, Salvatore T and Park, Jinsoo and Ram, Sudha},
	pages = {32},
	annote = {Design Science: Creating and evaluating IT artifacts allows researchers to better understand the underlying problem and find plausible theories, explanations, transformations etc.
 
What has to be included?
 
How to conduct DS?
 
How to evaluate DS?
 
How to design DS?},
	file = {Hevner et al. - Design Science in Information Systems Research.pdf:/home/andy/Zotero/storage/EBB4MPDU/Hevner et al. - Design Science in Information Systems Research.pdf:application/pdf}
}

@article{kaliszykEfficientSemanticFeaturesa,
	title = {Efficient {Semantic} {Features} for {Automated} {Reasoning} over {Large} {Theories}},
	abstract = {Large formal mathematical knowledge bases encode considerable parts of advanced mathematics and exact science, allowing deep semantic computer assistance and veriﬁcation of complicated theories down to the atomic logical rules. An essential part of automated reasoning over such large theories are methods learning selection of relevant knowledge from the thousands of proofs in the corpora. Such methods in turn rely on efﬁciently computable features characterizing the highly structured and inter-related mathematical statements.},
	language = {en},
	author = {Kaliszyk, Cezary and Urban, Josef and Vyskocil, Jiri},
	pages = {7},
	annote = {The most commonly used features for characterizing math-ematical statements in large theories are just theirsym-bols[Hoder and Voronkov, 2011; Meng and Paulson,2009]. In addition to that, large-theory ATP systems likeHOL(y)Hammer[Kaliszyk and Urban, 2014], Sledgeham-mer[K ̈uhlweinet al., 2013]and MaLARea[Urbanet al.,2008]have so far used features that represent:
•Types, i.e., type constants, type constructors, and typeclasses[Kaliszyk and Urban, 2014]
•Term walks of length 2[K ̈uhlweinet al., 2013]
•Subterms[Urbanet al., 2008]•Validity in a pool of finite models[Urbanet al., 2008]
•Meta-information such as the theory name and presencein various databases[K ̈uhlweinet al., 2013]
The normalizations for term and type variables that havebeen tried so far include:•Replacing variables by their (variable-normalized)types[Kaliszyk and Urban, 2014]
•Using de Bruijn indices[Urbanet al., 2008]
•Renaming all variables to a unique common vari-able[Urbanet al., 2008]•Using the original variable names (this is useful whenthe same variable names are used for similar purposes)
===================================
Uses Discrimination/Substitution trees for extracting efficient semantic features (unification/generalization of terms)},
	file = {Kaliszyk et al. - Efficient Semantic Features for Automated Reasonin.pdf:/home/andy/Zotero/storage/Q7PAQJDB/Kaliszyk et al. - Efficient Semantic Features for Automated Reasonin.pdf:application/pdf}
}

@article{balunovicLearningSolveSMT,
	title = {Learning to {Solve} {SMT} {Formulas}},
	abstract = {We present a new approach for learning to solve SMT formulas. We phrase the challenge of solving SMT formulas as a tree search problem where at each step a transformation is applied to the input formula until the formula is solved. Our approach works in two phases: ﬁrst, given a dataset of unsolved formulas we learn a policy that for each formula selects a suitable transformation to apply at each step in order to solve the formula, and second, we synthesize a strategy in the form of a loop-free program with branches. This strategy is an interpretable representation of the policy decisions and is used to guide the SMT solver to decide formulas more efﬁciently, without requiring any modiﬁcation to the solver itself and without needing to evaluate the learned policy at inference time. We show that our approach is effective in practice – it solves 17\% more formulas over a range of benchmarks and achieves up to 100× runtime improvement over a state-of-the-art SMT solver.},
	language = {en},
	author = {Balunovic, Mislav and Bielik, Pavol and Vechev, Martin},
	pages = {12},
	annote = {Bilinear Features:
-NGram
NN features:
-BOW on input formula, each token a word-AST with extraction of all subtrees of depth {\textless}2-Skip-Gram, average token embedding
 },
	file = {Balunovic et al. - Learning to Solve SMT Formulas.pdf:/home/andy/Zotero/storage/KM6S4E22/Balunovic et al. - Learning to Solve SMT Formulas.pdf:application/pdf}
}

@article{kimMindGapGenerative,
	title = {Mind the {Gap}: {A} {Generative} {Approach} to {Interpretable} {Feature} {Selection} and {Extraction}},
	abstract = {We present the Mind the Gap Model (MGM), an approach for interpretable feature extraction and selection. By placing interpretability criteria directly into the model, we allow for the model to both optimize parameters related to interpretability and to directly report a global set of distinguishable dimensions to assist with further data exploration and hypothesis generation. MGM extracts distinguishing features on real-world datasets of animal features, recipes ingredients, and disease co-occurrence. It also maintains or improves performance when compared to related approaches. We perform a user study with domain experts to show the MGM’s ability to help with dataset exploration.},
	language = {en},
	author = {Kim, Been and Shah, Julie A and Doshi-Velez, Finale},
	pages = {9},
	annote = {evtl. relevant für feature filtering, sonst eher nicht},
	file = {Kim et al. - Mind the Gap A Generative Approach to Interpretab.pdf:/home/andy/Zotero/storage/VKYNBJ8U/Kim et al. - Mind the Gap A Generative Approach to Interpretab.pdf:application/pdf}
}

@inproceedings{kaliszykStrongerAutomationFlyspeck,
	title = {Stronger {Automation} for {Flyspeck} by {Feature} {Weighting} and {Strategy} {Evolution}},
	url = {https://easychair.org/publications/paper/VZv6},
	doi = {10.29007/5gzr},
	abstract = {Two complementary AI methods are used to improve the strength of the AI/ATP service for proving conjectures over the HOL Light and Flyspeck corpora. First, several schemes for frequency-based feature weighting are explored in combination with distanceweighted k-nearest-neighbor classiﬁer. This results in 16\% improvement (39.0\% to 45.5\% Flyspeck problems solved) of the overall strength of the service when using 14 CPUs and 30 seconds. The best premise-selection/ATP combination is improved from 24.2\% to 31.4\%, i.e. by 30\%. A smaller improvement is obtained by evolving targetted E prover strategies on two particular premise selections, using the Blind Strategymaker (BliStr) system. This raises the performance of the best AI/ATP method from 31.4\% to 34.9\%, i.e. by 11\%, and raises the current 14-CPU power of the service to 46.9\%.},
	language = {en},
	urldate = {2019-07-09},
	author = {Kaliszyk, Cezary and Urban, Josef},
	pages = {87--77},
	annote = {Using IDF for symbol weighting aswell
 
-Different variants on IDF},
	file = {Kaliszyk and Urban - Stronger Automation for Flyspeck by Feature Weight.pdf:/home/andy/Zotero/storage/62BJHHYT/Kaliszyk and Urban - Stronger Automation for Flyspeck by Feature Weight.pdf:application/pdf}
}

@article{azizMachineLearningTechnique,
	title = {A {Machine} {Learning} {Technique} for {Hardness} {Estimation} of {QFBV} {SMT} {Problems} ({Work} in progress)},
	abstract = {In this paper, we present a new approach for measuring the expected runtimes (hardness) of SMT problems. The required features, the statistical hardness model used and the machine learning technique which we used are presented. The method is applied to estimate the hardness of problems in the Quanti er Free Bit Vector (QFBV) theory and we used four of the contesting solvers in SMTCOMP2011 to demonstrate the technique. We have qualitatively expanded some propositional SAT features existing in the literature to directly work on general SMT problem instances without preprocessing. Experimental results with the standard set of benchmarks are promising and our implementation proves the concept.},
	language = {en},
	author = {Aziz, Mohammad Abdul and Wassal, Amr and Darwish, Nevine},
	pages = {10},
	annote = {NANDS=The number of arguments to allthe ∧ functions in the SMTproblem.
NA=The number of asserted Formulas
NEQUAL=The summation of the number of the arguments to all the = functions in the SMT problem. This includes those whose arguments are boolean variables only.
NDISTINCT=The summation of the number of the arguments to all the distinct functions in the SMT problem (This has the same justications of the = function).
NIMPLY=The number of instances of → function in the SMT problem.
NXOR=The number of the xor functions in the SMT problem
NITE=The number of instances of ite function.ite(a,b,c) is equivalent to (b∨¬a)∧(a∨c)∧(b∨c)
NBOOL=Number of Boolean uninterpreted constants (These are variables to find a substitution for.)
NTHEORY−ATOMS=The number of theory atoms in the SMT problem (The justification for this is that; for the propositional SAT solver part of the SMT solver, the theory atoms are substituted and dealt with as if they are Boolean variables i.e. They are assigned the values either true or false).},
	file = {Aziz et al. - A Machine Learning Technique for Hardness Estimati.pdf:/home/andy/Zotero/storage/3DMV3HIK/Aziz et al. - A Machine Learning Technique for Hardness Estimati.pdf:application/pdf}
}

@article{lawsonWhatRoleInduction2005,
	title = {What is the role of induction and deduction in reasoning and scientific inquiry?},
	volume = {42},
	issn = {1098-2736},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/tea.20067},
	doi = {10.1002/tea.20067},
	abstract = {A long-standing and continuing controversy exists regarding the role of induction and deduction in reasoning and in scientific inquiry. Given the inherent difficulty in reconstructing reasoning patterns based on personal and historical accounts, evidence about the nature of human reasoning in scientific inquiry has been sought from a controlled experiment designed to identify the role played by enumerative induction and deduction in cognition as well as from the relatively new field of neural modeling. Both experimental results and the neurological models imply that induction across a limited set of observations plays no role in task performance and in reasoning. Therefore, support has been obtained for Popper's hypothesis that enumerative induction does not exist as a psychological process. Instead, people appear to process information in terms of increasingly abstract cycles of hypothetico-deductive reasoning. Consequently, science instruction should provide students with opportunities to generate and test increasingly complex and abstract hypotheses and theories in a hypothetico-deductive manner. In this way students can be expected to become increasingly conscious of their underlying hypothetico-deductive thought processes, increasingly skilled in their application, and hence increasingly scientifically literate. © 2005 Wiley Periodicals, Inc. J Res Sci Teach},
	language = {en},
	number = {6},
	urldate = {2019-07-09},
	journal = {Journal of Research in Science Teaching},
	author = {Lawson, Anton E.},
	year = {2005},
	pages = {716--740},
	annote = {wsl. nicht relevant},
	file = {Full Text PDF:/home/andy/Zotero/storage/MXJN9YM7/Lawson - 2005 - What is the role of induction and deduction in rea.pdf:application/pdf;Snapshot:/home/andy/Zotero/storage/GTKQ9KVW/tea.html:text/html}
}

@article{panSurveyTransferLearning2010,
	title = {A {Survey} on {Transfer} {Learning}},
	volume = {22},
	issn = {1041-4347},
	doi = {10.1109/TKDE.2009.191},
	abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
	number = {10},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Pan, S. J. and Yang, Q.},
	month = oct,
	year = {2010},
	keywords = {data mining, Data mining, Knowledge engineering, Training data, machine learning, survey, Machine learning, data mining., inductive transfer learning, knowledge engineering, knowledge transfer, Knowledge transfer, Labeling, learning by example, Learning systems, Machine learning algorithms, optimisation, Space technology, Testing, transductive transfer learning, Transfer learning, unsupervised learning, unsupervised transfer learning},
	pages = {1345--1359},
	file = {IEEE Xplore Abstract Record:/home/andy/Zotero/storage/NH2D79WJ/5288526.html:text/html;IEEE Xplore Full Text PDF:/home/andy/Zotero/storage/SL7N3KHH/Pan and Yang - 2010 - A Survey on Transfer Learning.pdf:application/pdf}
}

@inproceedings{harrisRecognizersExtractingArchitectural1995,
	title = {Recognizers for extracting architectural features from source code},
	doi = {10.1109/WCRE.1995.514713},
	abstract = {Architectural representation can play a pivotal role throughout the life cycle of any software program. In particular, we are interested in the role it plays in the maintenance/evolution of legacy programs. During these phases, analysts often describe programs using architectural terminology (e.g., "interfaces", "interprocess communication", "layers", "objects"). Our research and development goals center on supporting such activities through architectural recovery tools that are based on reverse engineering technology. These tools start with existing source code and extract architecture-level descriptions. We have implemented a framework for architectural recovery and our experience leads us to several observations about the representational needs of a library that is populated with families of architecture recognition rules. This paper characterizes the kinds of recognizers we have developed and describes an approach for rule parameterization and retrieval.},
	booktitle = {Proceedings of 2nd {Working} {Conference} on {Reverse} {Engineering}},
	author = {Harris, D. R. and Reubenstein, H. B. and Yeh, A. S.},
	month = jul,
	year = {1995},
	keywords = {feature extraction, Feature extraction, software maintenance, Software maintenance, architectural recovery tools, architectural representation, architecture recognition rules, architecture-level descriptions, Character recognition, Computer architecture, Indexing, legacy program evolution, library, Maintenance engineering, Research and development, reverse engineering, Reverse engineering, rule parameterization, rule retrieval, software libraries, Software libraries, software life cycle, software tools, source code, source code architectural feature extraction, Terminology},
	pages = {252--261},
	annote = {-Loops-Decomposables
Look for pieces of code/JavaDL that do something particular, e.g. smth with integers},
	file = {IEEE Xplore Abstract Record:/home/andy/Zotero/storage/6F8KSIBH/514713.html:text/html;IEEE Xplore Full Text PDF:/home/andy/Zotero/storage/67CTSCXL/Harris et al. - 1995 - Recognizers for extracting architectural features .pdf:application/pdf}
}

@inproceedings{weiSupervisedDeepFeatures2017,
	address = {Melbourne, Australia},
	title = {Supervised {Deep} {Features} for {Software} {Functional} {Clone} {Detection} by {Exploiting} {Lexical} and {Syntactical} {Information} in {Source} {Code}},
	isbn = {978-0-9992411-0-3},
	url = {https://www.ijcai.org/proceedings/2017/423},
	doi = {10.24963/ijcai.2017/423},
	abstract = {Software clone detection, aiming at identifying out code fragments with similar functionalities, has played an important role in software maintenance and evolution. Many clone detection approaches have been proposed. However, most of them represent source codes with hand-crafted features using lexical or syntactical information, or unsupervised deep features, which makes it difﬁcult to detect the functional clone pairs, i.e., pieces of codes with similar functionality but differing in both syntactical and lexical level. In this paper, we address the software functional clone detection problem by learning supervised deep features. We formulate the clone detection as a supervised learning to hash problem and propose an end-to-end deep feature learning framework called CDLH for functional clone detection. Such framework learns hash codes by exploiting the lexical and syntactical information for fast computation of functional similarity between code fragments. Experiments on software clone detection benchmarks indicate that the CDLH approach is effective and outperforms the state-of-the-art approaches in software functional clone detection.},
	language = {en},
	urldate = {2019-07-02},
	booktitle = {Proceedings of the {Twenty}-{Sixth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Wei, Huihui and Li, Ming},
	month = aug,
	year = {2017},
	pages = {3034--3040},
	annote = {Code features extracted with AST-LSTM:
    AST for syntactic features    LSTM for semantics of feature aggregations
Binary encoding -{\textgreater} Hamming Dist. for Duplicate Classification},
	file = {Wei and Li - 2017 - Supervised Deep Features for Software Functional C.pdf:/home/andy/Zotero/storage/EPA9HVWC/Wei and Li - 2017 - Supervised Deep Features for Software Functional C.pdf:application/pdf}
}

@book{margariaLeveragingApplicationsFormal2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Leveraging {Applications} of {Formal} {Methods}, {Verification} and {Validation}. {Verification}: 8th {International} {Symposium}, {ISoLA} 2018, {Limassol}, {Cyprus}, {November} 5-9, 2018, {Proceedings}, {Part} {II}},
	volume = {11245},
	isbn = {978-3-030-03420-7 978-3-030-03421-4},
	shorttitle = {Leveraging {Applications} of {Formal} {Methods}, {Verification} and {Validation}. {Verification}},
	url = {http://link.springer.com/10.1007/978-3-030-03421-4},
	language = {en},
	urldate = {2019-07-02},
	publisher = {Springer International Publishing},
	editor = {Margaria, Tiziana and Steffen, Bernhard},
	year = {2018},
	doi = {10.1007/978-3-030-03421-4},
	annote = {HasFloat
HasLoop
HasArray
HasComposite},
	file = {Margaria and Steffen - 2018 - Leveraging Applications of Formal Methods, Verific.pdf:/home/andy/Zotero/storage/ELN2FEEF/Margaria and Steffen - 2018 - Leveraging Applications of Formal Methods, Verific.pdf:application/pdf}
}

@article{shippeyAutomaticallyIdentifyingCode2019,
	title = {Automatically identifying code features for software defect prediction: {Using} {AST} {N}-grams},
	volume = {106},
	issn = {09505849},
	shorttitle = {Automatically identifying code features for software defect prediction},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584918302052},
	doi = {10.1016/j.infsof.2018.10.001},
	language = {en},
	urldate = {2019-07-02},
	journal = {Information and Software Technology},
	author = {Shippey, Thomas and Bowes, David and Hall, Tracy},
	month = feb,
	year = {2019},
	pages = {142--160},
	annote = {AST NGRAMS}
}

@article{botvinickHierarchicallyOrganizedBehavior2009,
	series = {Reinforcement learning and higher cognition},
	title = {Hierarchically organized behavior and its neural foundations: {A} reinforcement learning perspective},
	volume = {113},
	issn = {0010-0277},
	shorttitle = {Hierarchically organized behavior and its neural foundations},
	url = {http://www.sciencedirect.com/science/article/pii/S0010027708002059},
	doi = {10.1016/j.cognition.2008.08.011},
	abstract = {Research on human and animal behavior has long emphasized its hierarchical structure—the divisibility of ongoing behavior into discrete tasks, which are comprised of subtask sequences, which in turn are built of simple actions. The hierarchical structure of behavior has also been of enduring interest within neuroscience, where it has been widely considered to reflect prefrontal cortical functions. In this paper, we reexamine behavioral hierarchy and its neural substrates from the point of view of recent developments in computational reinforcement learning. Specifically, we consider a set of approaches known collectively as hierarchical reinforcement learning, which extend the reinforcement learning paradigm by allowing the learning agent to aggregate actions into reusable subroutines or skills. A close look at the components of hierarchical reinforcement learning suggests how they might map onto neural structures, in particular regions within the dorsolateral and orbital prefrontal cortex. It also suggests specific ways in which hierarchical reinforcement learning might provide a complement to existing psychological models of hierarchically structured behavior. A particularly important question that hierarchical reinforcement learning brings to the fore is that of how learning identifies new action routines that are likely to provide useful building blocks in solving a wide range of future problems. Here and at many other points, hierarchical reinforcement learning offers an appealing framework for investigating the computational and neural underpinnings of hierarchically structured behavior.},
	number = {3},
	urldate = {2019-06-21},
	journal = {Cognition},
	author = {Botvinick, Matthew M. and Niv, Yael and Barto, Andrew C.},
	month = dec,
	year = {2009},
	keywords = {Prefrontal cortex, Reinforcement learning},
	pages = {262--280},
	file = {Accepted Version:/home/andy/Zotero/storage/MEKTWTHJ/Botvinick et al. - 2009 - Hierarchically organized behavior and its neural f.pdf:application/pdf;ScienceDirect Snapshot:/home/andy/Zotero/storage/Q2AVXW55/S0010027708002059.html:text/html}
}

@misc{PromiseHierarchicalReinforcement2019,
	title = {The {Promise} of {Hierarchical} {Reinforcement} {Learning}},
	url = {https://thegradient.pub/the-promise-of-hierarchical-reinforcement-learning/},
	abstract = {This idea of temporal abstraction, once incorporated into reinforcement learning (RL), converts it into *hierarchical* reinforcement learning (HRL).},
	language = {en},
	urldate = {2019-06-21},
	journal = {The Gradient},
	month = mar,
	year = {2019},
	file = {Snapshot:/home/andy/Zotero/storage/GAVN9FEH/the-promise-of-hierarchical-reinforcement-learning.html:text/html}
}

@article{dietterichHierarchicalReinforcementLearning1999,
	title = {Hierarchical {Reinforcement} {Learning} with the {MAXQ} {Value} {Function} {Decomposition}},
	url = {http://arxiv.org/abs/cs/9905014},
	abstract = {This paper presents a new approach to hierarchical reinforcement learning based on decomposing the target Markov decision process (MDP) into a hierarchy of smaller MDPs and decomposing the value function of the target MDP into an additive combination of the value functions of the smaller MDPs. The decomposition, known as the MAXQ decomposition, has both a procedural semantics—as a subroutine hierarchy—and a declarative semantics—as a representation of the value function of a hierarchical policy. MAXQ uniﬁes and extends previous work on hierarchical reinforcement learning by Singh, Kaelbling, and Dayan and Hinton. It is based on the assumption that the programmer can identify useful subgoals and deﬁne subtasks that achieve these subgoals. By deﬁning such subgoals, the programmer constrains the set of policies that need to be considered during reinforcement learning. The MAXQ value function decomposition can represent the value function of any policy that is consistent with the given hierarchy. The decomposition also creates opportunities to exploit state abstractions, so that individual MDPs within the hierarchy can ignore large parts of the state space. This is important for the practical application of the method. This paper deﬁnes the MAXQ hierarchy, proves formal results on its representational power, and establishes ﬁve conditions for the safe use of state abstractions. The paper presents an online model-free learning algorithm, MAXQ-Q, and proves that it converges wih probability 1 to a kind of locally-optimal policy known as a recursively optimal policy, even in the presence of the ﬁve kinds of state abstraction. The paper evaluates the MAXQ representation and MAXQ-Q through a series of experiments in three domains and shows experimentally that MAXQ-Q (with state abstractions) converges to a recursively optimal policy much faster than ﬂat Q learning. The fact that MAXQ learns a representation of the value function has an important beneﬁt: it makes it possible to compute and execute an improved, non-hierarchical policy via a procedure similar to the policy improvement step of policy iteration. The paper demonstrates the eﬀectiveness of this non-hierarchical execution experimentally. Finally, the paper concludes with a comparison to related work and a discussion of the design tradeoﬀs in hierarchical reinforcement learning.},
	language = {en},
	urldate = {2019-06-21},
	journal = {arXiv:cs/9905014},
	author = {Dietterich, Thomas G.},
	month = may,
	year = {1999},
	note = {arXiv: cs/9905014},
	keywords = {Computer Science - Machine Learning, I.2.6},
	file = {Dietterich - 1999 - Hierarchical Reinforcement Learning with the MAXQ .pdf:/home/andy/Zotero/storage/HHNK4Z3V/Dietterich - 1999 - Hierarchical Reinforcement Learning with the MAXQ .pdf:application/pdf}
}

@article{baconOptionCriticArchitecture2016,
	title = {The {Option}-{Critic} {Architecture}},
	url = {http://arxiv.org/abs/1609.05140},
	abstract = {Temporal abstraction is key to scaling up learning and planning in reinforcement learning. While planning with temporally extended actions is well understood, creating such abstractions autonomously from data has remained challenging. We tackle this problem in the framework of options [Sutton, Precup \& Singh, 1999; Precup, 2000]. We derive policy gradient theorems for options and propose a new option-critic architecture capable of learning both the internal policies and the termination conditions of options, in tandem with the policy over options, and without the need to provide any additional rewards or subgoals. Experimental results in both discrete and continuous environments showcase the ﬂexibility and efﬁciency of the framework.},
	language = {en},
	urldate = {2019-06-21},
	journal = {arXiv:1609.05140 [cs]},
	author = {Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.05140},
	keywords = {Computer Science - Artificial Intelligence},
	file = {Bacon et al. - 2016 - The Option-Critic Architecture.pdf:/home/andy/Zotero/storage/GWC35W4U/Bacon et al. - 2016 - The Option-Critic Architecture.pdf:application/pdf}
}

@article{lagoudakisReinforcementLearningClassification,
	title = {Reinforcement {Learning} as {Classification}: {Leveraging} {Modern} {Classifiers}},
	abstract = {The basic tools of machine learning appear in the inner loop of most reinforcement learning algorithms, typically in the form of Monte Carlo methods or function approximation techniques. To a large extent, however, current reinforcement learning algorithms draw upon machine learning techniques that are at least ten years old and, with a few exceptions, very little has been done to exploit recent advances in classiﬁcation learning for the purposes of reinforcement learning. We use a variant of approximate policy iteration based on rollouts that allows us to use a pure classiﬁcation learner, such as a support vector machine (SVM), in the inner loop of the algorithm. We argue that the use of SVMs, particularly in combination with the kernel trick, can make it easier to apply reinforcement learning as an “outof-the-box” technique, without extensive feature engineering. Our approach opens the door to modern classiﬁcation methods, but does not preclude the use of classical methods. We present experimental results in the pendulum balancing and bicycle riding domains using both SVMs and neural networks for classiﬁers.},
	language = {en},
	author = {Lagoudakis, Michail and Parr, Ronald},
	pages = {8},
	file = {Lagoudakis and Parr - Reinforcement Learning as Classification Leveragi.pdf:/home/andy/Zotero/storage/X6UH7ZZW/Lagoudakis and Parr - Reinforcement Learning as Classification Leveragi.pdf:application/pdf}
}

@article{pitisRethinkingDiscountFactor2019,
	title = {Rethinking the {Discount} {Factor} in {Reinforcement} {Learning}: {A} {Decision} {Theoretic} {Approach}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Rethinking the {Discount} {Factor} in {Reinforcement} {Learning}},
	url = {https://aaai.org/ojs/index.php/AAAI/article/view/4795},
	doi = {10.1609/aaai.v33i01.33017949},
	abstract = {Reinforcement learning (RL) agents have traditionally been tasked with maximizing the value function of a Markov decision process (MDP), either in continuous settings, with ﬁxed discount factor γ {\textless} 1, or in episodic settings, with γ = 1. While this has proven effective for speciﬁc tasks with welldeﬁned objectives (e.g., games), it has never been established that ﬁxed discounting is suitable for general purpose use (e.g., as a model of human preferences). This paper characterizes rationality in sequential decision making using a set of seven axioms and arrives at a form of discounting that generalizes traditional ﬁxed discounting. In particular, our framework admits a state-action dependent “discount” factor that is not constrained to be less than 1, so long as there is eventual long run discounting. Although this broadens the range of possible preference structures in continuous settings, we show that there exists a unique “optimizing MDP” with ﬁxed γ {\textless} 1 whose optimal value function matches the true utility of the optimal policy, and we quantify the difference between value and utility for suboptimal policies. Our work can be seen as providing a normative justiﬁcation for (a slight generalization of) Martha White’s RL task formalism (2017) and other recent departures from the traditional RL, and is relevant to task speciﬁcation in RL, inverse RL and preference-based RL.},
	language = {en},
	urldate = {2020-01-07},
	journal = {AAAI},
	author = {Pitis, Silviu},
	month = jul,
	year = {2019},
	pages = {7949--7956},
	file = {Pitis - 2019 - Rethinking the Discount Factor in Reinforcement Le.pdf:/home/andy/Zotero/storage/6AFGM38X/Pitis - 2019 - Rethinking the Discount Factor in Reinforcement Le.pdf:application/pdf}
}

@misc{TwoKindsUncertainty2015,
	title = {The {Two} {Kinds} of {Uncertainty} an {AI} {Agent} {Has} to {Represent}},
	url = {https://www.inference.vc/the-two-kinds-of-uncertainties-in-reinforcement-learning-2/},
	abstract = {AI agents have to act in non-deterministic environments: a self-driving car cannot be 100\% confident what other cars or pedestrians are going to do;in medicine, the measurable data are often insufficient to predict the outcome of a treatment with full certainty. It kind of goes without saying that AI...},
	language = {en},
	urldate = {2020-01-07},
	journal = {inFERENCe},
	month = aug,
	year = {2015},
	file = {Snapshot:/home/andy/Zotero/storage/GR4MPBRQ/the-two-kinds-of-uncertainties-in-reinforcement-learning-2.html:text/html}
}

@inproceedings{singhHybridFrameworkFunctional2019,
	address = {Tysons Corner, VA, USA},
	series = {{GLSVLSI} '19},
	title = {A {Hybrid} {Framework} for {Functional} {Verification} using {Reinforcement} {Learning} and {Deep} {Learning}},
	isbn = {978-1-4503-6252-8},
	url = {https://doi.org/10.1145/3299874.3318039},
	doi = {10.1145/3299874.3318039},
	abstract = {In this paper, we propose a novel hybrid verification framework (HVF) which uses Reinforcement Learning (RL) and Deep Neural Networks (DNNs) to accelerate the verification of complex systems. More precisely, our HVF incorporates RL to generate all possible sequences of vectors needed to approach a target state as well as the corresponding path to the target state which contains a potential design error. Furthermore, HVF utilizes DNNs to accelerate the verification of complex data paths in the target states. We have tested our framework on several circuits including multi-core designs as well as bus-arbiters and confirmed its significant verification speedup when compared to prior work. For example, HVF provides a total speedup of 4.5x for a quad-core MIPS processor verification.},
	urldate = {2020-03-03},
	booktitle = {Proceedings of the 2019 on {Great} {Lakes} {Symposium} on {VLSI}},
	publisher = {Association for Computing Machinery},
	author = {Singh, Karunveer and Gupta, Rishabh and Gupta, Vikram and Fayyazi, Arash and Pedram, Massoud and Nazarian, Shahin},
	month = may,
	year = {2019},
	keywords = {assertions, coverage directed test generation, deep neural networks, reinforcement learning, sat solver},
	pages = {367--370},
	file = {Full Text PDF:/home/andy/Zotero/storage/G49RGQHC/Singh et al. - 2019 - A Hybrid Framework for Functional Verification usi.pdf:application/pdf}
}

@article{brockmanOpenAIGym2016,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@misc{stable-baselines,
  author = {Hill, Ashley and Raffin, Antonin and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Traore, Rene and Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {Stable Baselines},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/hill-a/stable-baselines}},
}

@article{chenRelationalVerificationUsing2019,
	title = {Relational verification using reinforcement learning},
	volume = {3},
	url = {https://doi.org/10.1145/3360567},
	doi = {10.1145/3360567},
	abstract = {Relational verification aims to prove properties that relate a pair of programs or two different runs of the same program. While relational properties (e.g., equivalence, non-interference) can be verified by reducing them to standard safety, there are typically many possible reduction strategies, only some of which result in successful automated verification. Motivated by this problem, we propose a novel relational verification algorithm that learns useful reduction strategies using reinforcement learning. Specifically, we show how to formulate relational verification as a Markov Decision Process (MDP) and use reinforcement learning to synthesize an optimal policy for the underlying MDP. The learned policy is then used to guide the search for a successful verification strategy. We have implemented this approach in a tool called Coeus and evaluate it on two benchmark suites. Our evaluation shows that Coeus solves significantly more problems within a given time limit compared to multiple baselines, including two state-of-the-art relational verification tools.},
	number = {OOPSLA},
	urldate = {2020-03-03},
	journal = {Proc. ACM Program. Lang.},
	author = {Chen, Jia and Wei, Jiayi and Feng, Yu and Bastani, Osbert and Dillig, Isil},
	month = oct,
	year = {2019},
	keywords = {reinforcement learning, neural network, policy gradient, proof search, relational property, verification},
	pages = {141:1--141:30},
	file = {Full Text PDF:/home/andy/Zotero/storage/YYCZK7HD/Chen et al. - 2019 - Relational verification using reinforcement learni.pdf:application/pdf}
}

@inproceedings{somenziReinforcementLearningFormal2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Reinforcement {Learning} and {Formal} {Requirements}},
	isbn = {978-3-030-28423-7},
	doi = {10.1007/978-3-030-28423-7\_2},
	abstract = {Reinforcement learning is an approach to controller synthesis where agents rely on reward signals to choose actions in order to satisfy the requirements implicit in reward signals. Oftentimes non-experts have to come up with the requirements and their translation to rewards under significant time pressure, even though manual translation is time consuming and error prone. For safety-critical applications of reinforcement learning a rigorous design methodology is needed and, in particular, a principled approach to requirement specification and to the translation of objectives into the form required by reinforcement learning algorithms.Formal logic provides a foundation for the rigorous and unambiguous requirement specification of learning objectives. However, reinforcement learning algorithms require requirements to be expressed as scalar reward signals. We discuss a recent technique, called limit-reachability, that bridges this gap by faithfully translating logic-based requirements into the scalar reward form needed in model-free reinforcement learning. This technique enables the synthesis of controllers that maximize the probability to satisfy given logical requirements using off-the-shelf, model-free reinforcement learning algorithms.},
	language = {en},
	booktitle = {Numerical {Software} {Verification}},
	publisher = {Springer International Publishing},
	author = {Somenzi, Fabio and Trivedi, Ashutosh},
	editor = {Zamani, Majid and Zufferey, Damien},
	year = {2019},
	pages = {26--41},
	file = {Springer Full Text PDF:/home/andy/Zotero/storage/6D8NZS9E/Somenzi and Trivedi - 2019 - Reinforcement Learning and Formal Requirements.pdf:application/pdf}
}

@inproceedings{huHFMVHybridizingFormal2018,
	address = {San Francisco, California},
	series = {{DAC} '18},
	title = {{HFMV}: hybridizing formal methods and machine learning for verification of analog and mixed-signal circuits},
	isbn = {978-1-4503-5700-5},
	shorttitle = {{HFMV}},
	url = {https://doi.org/10.1145/3195970.3196059},
	doi = {10.1145/3195970.3196059},
	abstract = {With increasing design complexity and robustness requirement, analog and mixed-signal (AMS) verification manifests itself as a key bottleneck. While formal methods and machine learning have been proposed for AMS verification, these two techniques suffer from their own limitations, with the former being specifically limited by scalability and the latter by the inherent uncertainty in learning-based models. We present a new direction in AMS verification by proposing a hybrid formal/machine-learning verification technique (HFMV) to combine the best of the two worlds. HFMV adds formalism on the top of a probabilistic learning model while providing a sense of coverage for extremely rare failure detection. HFMV intelligently and iteratively reduces uncertainty of the learning model by a proposed formally-guided active learning strategy and discovers potential rare failure regions in complex high-dimensional parameter spaces. It leads to reliable failure prediction in the case of a failing circuit, or a high-confidence pass decision in the case of a good circuit. We demonstrate that HFMV is able to employ a modest amount of data to identify hard-to-find rare failures which are completely missed by state-of-the-art sampling methods even with high volume sampling data.},
	urldate = {2020-03-03},
	booktitle = {Proceedings of the 55th {Annual} {Design} {Automation} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Hu, Hanbin and Zheng, Qingran and Wang, Ya and Li, Peng},
	month = jun,
	year = {2018},
	pages = {1--6},
	file = {Full Text PDF:/home/andy/Zotero/storage/B3Z62G46/Hu et al. - 2018 - HFMV hybridizing formal methods and machine learn.pdf:application/pdf}
}

@article{gabmeyerFeaturebasedClassificationFormal2019a,
	title = {A feature-based classification of formal verification techniques for software models},
	volume = {18},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-017-0591-z},
	doi = {10.1007/s10270-017-0591-z},
	abstract = {Software models are the core development artifact in model-based engineering (MBE). The MBE paradigm promotes the use of software models to describe structure and behavior of the system under development and proposes the automatic generation of executable code from the models. Thus, defects in the models most likely propagate to executable code. To detect defects already at the modeling level, many approaches propose to use formal verification techniques to ensure the correctness of these models. These approaches are the subject of this survey. We review the state of the art of formal verification techniques for software models and provide a feature-based classification that allows us to categorize and compare the different approaches.},
	language = {en},
	number = {1},
	urldate = {2020-03-03},
	journal = {Softw Syst Model},
	author = {Gabmeyer, Sebastian and Kaufmann, Petra and Seidl, Martina and Gogolla, Martin and Kappel, Gerti},
	month = feb,
	year = {2019},
	pages = {473--498},
	file = {Springer Full Text PDF:/home/andy/Zotero/storage/IFTAV5E9/Gabmeyer et al. - 2019 - A feature-based classification of formal verificat.pdf:application/pdf}
}

@article{rodriguezSoftwareVerificationValidation2019,
	title = {Software {Verification} and {Validation} {Technologies} and {Tools}},
	volume = {36},
	issn = {1937-4194},
	doi = {10.1109/MS.2018.2883354},
	abstract = {Software quality matters-more than ever. Software has become the most crucial infrastructure in this century. All businesses is software businesses because they based their operations and services in the Internet of Things, business intelligence (BI), artificial intelligence, cloud computing, social networks, and so forth. Classic IT and embedded systems are converging toward ubiquitous software. Systems will be connected and thus increasingly missing critical. The digital transformation across industries depends on systems performing according to their requirements and needs. This importance of software quality has grown considerably over recent years.},
	number = {2},
	journal = {IEEE Software},
	author = {Rodriguez, Moises and Piattini, Mario and Ebert, Christof},
	month = mar,
	year = {2019},
	keywords = {artificial intelligence, classic IT embedded systems, cloud computing, competitive intelligence, crucial infrastructure, embedded systems, Internet, Internet of Things, ISO Standards, Quality assessment, social networking (online), social networks, software businesses, software quality, Software quality, Software testing, software verification, Static analysis, ubiquitous computing, ubiquitous software},
	pages = {13--24},
	file = {IEEE Xplore Abstract Record:/home/andy/Zotero/storage/XCWV94EP/8648264.html:text/html}
}

@article{francois-lavetIntroductionDeepReinforcement2018,
	title = {An {Introduction} to {Deep} {Reinforcement} {Learning}},
	volume = {11},
	issn = {1935-8237, 1935-8245},
	url = {http://arxiv.org/abs/1811.12560},
	doi = {10.1561/2200000071},
	abstract = {Deep reinforcement learning is the combination of reinforcement learning (RL) and deep learning. This field of research has been able to solve a wide range of complex decision-making tasks that were previously out of reach for a machine. Thus, deep RL opens up many new applications in domains such as healthcare, robotics, smart grids, finance, and many more. This manuscript provides an introduction to deep reinforcement learning models, algorithms and techniques. Particular focus is on the aspects related to generalization and how deep RL can be used for practical applications. We assume the reader is familiar with basic machine learning concepts.},
	number = {3-4},
	urldate = {2020-03-16},
	journal = {FNT in Machine Learning},
	author = {Francois-Lavet, Vincent and Henderson, Peter and Islam, Riashat and Bellemare, Marc G. and Pineau, Joelle},
	year = {2018},
	note = {arXiv: 1811.12560},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {219--354},
	file = {arXiv Fulltext PDF:/home/andy/Zotero/storage/XAI2J946/Francois-Lavet et al. - 2018 - An Introduction to Deep Reinforcement Learning.pdf:application/pdf;arXiv.org Snapshot:/home/andy/Zotero/storage/UCPUUNVG/1811.html:text/html}
}

@article{mnihHumanlevelControlDeep2015,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14236},
	doi = {10.1038/nature14236},
	abstract = {An artificial agent is developed that learns to play\&nbsp;a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a\&nbsp;performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.},
	language = {en},
	number = {7540},
	urldate = {2020-03-16},
	journal = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	month = feb,
	year = {2015},
	note = {Number: 7540
Publisher: Nature Publishing Group},
	pages = {529--533},
	file = {Full Text PDF:/home/andy/Zotero/storage/KN4ZSVDN/Mnih et al. - 2015 - Human-level control through deep reinforcement lea.pdf:application/pdf;Snapshot:/home/andy/Zotero/storage/P929SCVR/nature14236.html:text/html}
}

@article{schmidhuberDeepLearningNeural2015,
	title = {Deep {Learning} in {Neural} {Networks}: {An} {Overview}},
	volume = {61},
	issn = {08936080},
	shorttitle = {Deep {Learning} in {Neural} {Networks}},
	url = {http://arxiv.org/abs/1404.7828},
	doi = {10.1016/j.neunet.2014.09.003},
	abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
	urldate = {2020-03-16},
	journal = {Neural Networks},
	author = {Schmidhuber, Juergen},
	month = jan,
	year = {2015},
	note = {arXiv: 1404.7828},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	pages = {85--117},
	annote = {Comment: 88 pages, 888 references},
	file = {arXiv Fulltext PDF:/home/andy/Zotero/storage/IJSBACPS/Schmidhuber - 2015 - Deep Learning in Neural Networks An Overview.pdf:application/pdf;arXiv.org Snapshot:/home/andy/Zotero/storage/36CS47IL/1404.html:text/html}
}

@article{farberInternalGuidanceSatallax2016,
	title = {Internal {Guidance} for {Satallax}},
	url = {http://arxiv.org/abs/1605.09293},
	abstract = {We propose a new internal guidance method for automated theorem provers based on the given-clause algorithm. Our method influences the choice of unprocessed clauses using positive and negative examples from previous proofs. To this end, we present an efficient scheme for Naive Bayesian classification by generalising label occurrences to types with monoid structure. This makes it possible to extend existing fast classifiers, which consider only positive examples, with negative ones. We implement the method in the higher-order logic prover Satallax, where we modify the delay with which propositions are processed. We evaluated our method on a simply-typed higher-order logic version of the Flyspeck project, where it solves 26\% more problems than Satallax without internal guidance.},
	urldate = {2020-03-16},
	journal = {arXiv:1605.09293 [cs]},
	author = {Färber, Michael and Brown, Chad},
	month = may,
	year = {2016},
	note = {arXiv: 1605.09293},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Logic in Computer Science},
	file = {arXiv Fulltext PDF:/home/andy/Zotero/storage/G7N443RY/Färber and Brown - 2016 - Internal Guidance for Satallax.pdf:application/pdf;arXiv.org Snapshot:/home/andy/Zotero/storage/SU3B5IC3/1605.html:text/html}
}

@inproceedings{brownSatallaxAutomaticHigherOrder2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Satallax: {An} {Automatic} {Higher}-{Order} {Prover}},
	isbn = {978-3-642-31365-3},
	shorttitle = {Satallax},
	doi = {10.1007/978-3-642-31365-3\_11},
	abstract = {Satallax is an automatic higher-order theorem prover that generates propositional clauses encoding (ground) tableau rules and uses MiniSat to test for unsatisfiability. We describe the implementation, focusing on flags that control search and examples that illustrate how the search proceeds.},
	language = {en},
	booktitle = {Automated {Reasoning}},
	publisher = {Springer},
	author = {Brown, Chad E.},
	editor = {Gramlich, Bernhard and Miller, Dale and Sattler, Uli},
	year = {2012},
	keywords = {higher-order logic, higher-order theorem proving, simple type theory},
	pages = {111--117}
}

@incollection{ohActionConditionalVideoPrediction2015,
	title = {Action-{Conditional} {Video} {Prediction} using {Deep} {Networks} in {Atari} {Games}},
	urldate = {2020-03-17},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 28},
	publisher = {Curran Associates, Inc.},
	author = {Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard L and Singh, Satinder},
	editor = {Cortes, C. and Lawrence, N. D. and Lee, D. D. and Sugiyama, M. and Garnett, R.},
	year = {2015},
	pages = {2863--2871},
	file = {NIPS Full Text PDF:/home/andy/Zotero/storage/44Z4YPTT/Oh et al. - 2015 - Action-Conditional Video Prediction using Deep Net.pdf:application/pdf;NIPS Snapshot:/home/andy/Zotero/storage/9UITI2UA/5859-action-conditional-video-prediction-using-deep-networks-in-atari-games.html:text/html}
}

@article{guoGeneratingTextDeep2015,
	title = {Generating {Text} with {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1510.09202},
	abstract = {We introduce a novel schema for sequence to sequence learning with a Deep Q-Network (DQN), which decodes the output sequence iteratively. The aim here is to enable the decoder to first tackle easier portions of the sequences, and then turn to cope with difficult parts. Specifically, in each iteration, an encoder-decoder Long Short-Term Memory (LSTM) network is employed to, from the input sequence, automatically create features to represent the internal states of and formulate a list of potential actions for the DQN. Take rephrasing a natural sentence as an example. This list can contain ranked potential words. Next, the DQN learns to make decision on which action (e.g., word) will be selected from the list to modify the current decoded sequence. The newly modified output sequence is subsequently used as the input to the DQN for the next decoding iteration. In each iteration, we also bias the reinforcement learning's attention to explore sequence portions which are previously difficult to be decoded. For evaluation, the proposed strategy was trained to decode ten thousands natural sentences. Our experiments indicate that, when compared to a left-to-right greedy beam search LSTM decoder, the proposed method performed competitively well when decoding sentences from the training set, but significantly outperformed the baseline when decoding unseen sentences, in terms of BLEU score obtained.},
	urldate = {2020-03-17},
	journal = {arXiv:1510.09202 [cs]},
	author = {Guo, Hongyu},
	month = oct,
	year = {2015},
	note = {arXiv: 1510.09202},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computation and Language},
	annote = {Comment: Accepted to the NIPS2015 Deep Reinforcement Learning Workshop},
	file = {arXiv Fulltext PDF:/home/andy/Zotero/storage/9PP94VLR/Guo - 2015 - Generating Text with Deep Reinforcement Learning.pdf:application/pdf;arXiv.org Snapshot:/home/andy/Zotero/storage/RTBNM8MR/1510.html:text/html}
}

@article{silverMasteringGameGo2017,
	title = {Mastering the game of {Go} without human knowledge},
	volume = {550},
	copyright = {2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature24270},
	doi = {10.1038/nature24270},
	abstract = {Starting from zero knowledge and without human data, AlphaGo Zero was able to teach itself to play Go and to develop novel strategies that provide new insights into the oldest of games.},
	language = {en},
	number = {7676},
	urldate = {2020-03-17},
	journal = {Nature},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and Driessche, George van den and Graepel, Thore and Hassabis, Demis},
	month = oct,
	year = {2017},
	note = {Number: 7676
Publisher: Nature Publishing Group},
	pages = {354--359},
	file = {Full Text PDF:/home/andy/Zotero/storage/7JIANLXS/Silver et al. - 2017 - Mastering the game of Go without human knowledge.pdf:application/pdf;Snapshot:/home/andy/Zotero/storage/IDBZTMAU/nature24270.html:text/html}
}

@inproceedings{kahnSelfSupervisedDeepReinforcement2018a,
	title = {Self-{Supervised} {Deep} {Reinforcement} {Learning} with {Generalized} {Computation} {Graphs} for {Robot} {Navigation}},
	doi = {10.1109/ICRA.2018.8460655},
	abstract = {Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and N-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Kahn, Gregory and Villaflor, Adam and Ding, Bosen and Abbeel, Pieter and Levine, Sergey},
	month = may,
	year = {2018},
	note = {ISSN: 2577-087X},
	keywords = {Planning, learning (artificial intelligence), Computational modeling, double Q-learning, generalized computation graph, internal map, Learning (artificial intelligence), learning-based methods, mobile robots, model-based methods, Navigation, path planning, planning method, Prediction algorithms, robot navigation, robot vision, Robots, self-supervised deep reinforcement learning, self-supervised training, Task analysis, value-based model-free methods},
	pages = {5129--5136},
	file = {IEEE Xplore Full Text PDF:/home/andy/Zotero/storage/NFM9GZAY/Kahn et al. - 2018 - Self-Supervised Deep Reinforcement Learning with G.pdf:application/pdf;IEEE Xplore Abstract Record:/home/andy/Zotero/storage/HGEQCRMA/8460655.html:text/html}
}

@article{crouseDeepReinforcementLearning2020,
	title = {A {Deep} {Reinforcement} {Learning} based {Approach} to {Learning} {Transferable} {Proof} {Guidance} {Strategies}},
	url = {http://arxiv.org/abs/1911.02065},
	abstract = {Traditional first-order logic (FOL) reasoning systems usually rely on manual heuristics for proof guidance. We propose TRAIL: a system that learns to perform proof guidance using reinforcement learning. A key design principle of our system is that it is general enough to allow transfer to problems in different domains that do not share the same vocabulary of the training set. To do so, we developed a novel representation of the internal state of a prover in terms of clauses and inference actions. We also propose a novel neural-based attention mechanism to learn interactions between clauses. We demonstrate that this approach enables the system to generalize from training to test data across domains with different vocabularies, suggesting that the neural architecture in TRAIL is well suited for representing and processing of logical formalisms. We also show that TRAIL's learned strategies provide a comparable performance to an established heuristics-based theorem prover.},
	urldate = {2020-03-17},
	journal = {arXiv:1911.02065 [cs]},
	author = {Crouse, Maxwell and Abdelaziz, Ibrahim and Makni, Bassem and Whitehead, Spencer and Cornelio, Cristina and Kapanipathi, Pavan and Pell, Edwin and Srinivas, Kavitha and Thost, Veronika and Witbrock, Michael and Fokoue, Achille},
	month = feb,
	year = {2020},
	note = {arXiv: 1911.02065},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Logic in Computer Science},
	file = {arXiv Fulltext PDF:/home/andy/Zotero/storage/UV2WIB4V/Crouse et al. - 2020 - A Deep Reinforcement Learning based Approach to Le.pdf:application/pdf;arXiv.org Snapshot:/home/andy/Zotero/storage/STQ9ANBM/1911.html:text/html}
}

@inproceedings{baumgartnerBeagleHierarchicSuperposition2015,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Beagle – {A} {Hierarchic} {Superposition} {Theorem} {Prover}},
	isbn = {978-3-319-21401-6},
	doi = {10.1007/978-3-319-21401-6\_25},
	abstract = {Beagle is an automated theorem prover for first-order logic modulo built-in theories. It implements a refined version of the hierarchic superposition calculus. This system description focuses on Beagle ’s proof procedure, background reasoning facilities, implementation, and experimental results.},
	language = {en},
	booktitle = {Automated {Deduction} - {CADE}-25},
	publisher = {Springer International Publishing},
	author = {Baumgartner, Peter and Bax, Joshua and Waldmann, Uwe},
	editor = {Felty, Amy P. and Middeldorp, Aart},
	year = {2015},
	pages = {367--377},
	file = {Submitted Version:/home/andy/Zotero/storage/DS6EHX8Y/Baumgartner et al. - 2015 - Beagle – A Hierarchic Superposition Theorem Prover.pdf:application/pdf}
}

@article{mnihPlayingAtariDeep2013,
	title = {Playing {Atari} with {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1312.5602},
	abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	urldate = {2020-03-20},
	journal = {arXiv:1312.5602 [cs]},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.5602},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: NIPS Deep Learning Workshop 2013},
	file = {arXiv Fulltext PDF:/home/andy/Zotero/storage/EQD8UKUS/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:application/pdf;arXiv.org Snapshot:/home/andy/Zotero/storage/JPRR5K6I/1312.html:text/html}
}

@article{vanhasseltDeepReinforcementLearning2015,
	title = {Deep {Reinforcement} {Learning} with {Double} {Q}-learning},
	url = {http://arxiv.org/abs/1509.06461},
	abstract = {The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.},
	urldate = {2020-04-07},
	journal = {arXiv:1509.06461 [cs]},
	author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
	month = dec,
	year = {2015},
	note = {arXiv: 1509.06461},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: AAAI 2016},
	file = {arXiv Fulltext PDF:/home/andy/Zotero/storage/P9VEMLGB/van Hasselt et al. - 2015 - Deep Reinforcement Learning with Double Q-learning.pdf:application/pdf;arXiv.org Snapshot:/home/andy/Zotero/storage/W65CJJ79/1509.html:text/html}
}

@article{schaulPrioritizedExperienceReplay2016,
	title = {Prioritized {Experience} {Replay}},
	url = {http://arxiv.org/abs/1511.05952},
	abstract = {Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games.},
	urldate = {2020-04-07},
	journal = {arXiv:1511.05952 [cs]},
	author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	month = feb,
	year = {2016},
	note = {arXiv: 1511.05952},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published at ICLR 2016},
	file = {arXiv Fulltext PDF:/home/andy/Zotero/storage/4L32LCSS/Schaul et al. - 2016 - Prioritized Experience Replay.pdf:application/pdf;arXiv.org Snapshot:/home/andy/Zotero/storage/BQTV68Q3/1511.html:text/html}
}